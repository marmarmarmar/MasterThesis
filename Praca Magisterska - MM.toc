\select@language {polish}
\contentsline {chapter}{\numberline {1}Historia}{7}
\contentsline {section}{\numberline {1.1}Pocz\k atki i perceptron}{7}
\contentsline {section}{\numberline {1.2}Zima sztucznej inteligencji}{7}
\contentsline {section}{\numberline {1.3}Dlaczego perceptron zawi\'od\IeC {\l }?}{8}
\contentsline {section}{\numberline {1.4}Algorytm wstecznej propagacji - odrodzenie i ponowna zima}{8}
\contentsline {section}{\numberline {1.5}Dlaczego sieci ponownie zawiod\IeC {\l }y?}{9}
\contentsline {chapter}{\numberline {2}Matematyczne podstawy algorytm\'ow}{11}
\contentsline {section}{\numberline {2.1}Uczenie}{11}
\contentsline {subsection}{\numberline {2.1.1}Formalna definicja uczenia}{11}
\contentsline {subsection}{\numberline {2.1.2}Uczenie z nadzorem}{12}
\contentsline {subsection}{\numberline {2.1.3}Uczenie bez nadzoru}{13}
\contentsline {subsection}{\numberline {2.1.4}Generalizacja oraz przeuczenie}{13}
\contentsline {subsection}{\numberline {2.1.5}Optymalizacja gradientowa}{14}
\contentsline {subsection}{\numberline {2.1.6}Stochastyczna optymalizacja gradientowa}{14}
\contentsline {section}{\numberline {2.2}Sztuczne Sieci neuronowe}{15}
\contentsline {subsection}{\numberline {2.2.1}Biologiczna motywacja}{15}
\contentsline {subsection}{\numberline {2.2.2}Perceptron}{15}
\contentsline {subsubsection}{Czym jest perceptron?}{15}
\contentsline {subsubsection}{Sigmoidalna funkcja aktywacji}{16}
\contentsline {subsubsection}{Klasyfikacja przy u\.zyciu perceptronu.}{17}
\contentsline {subsubsection}{Algorytm uczenia perceptronu.}{17}
\contentsline {section}{\numberline {2.3}Klasyczne sieci neuronowe oraz algorytm wstecznej propagacji}{18}
\contentsline {subsection}{\numberline {2.3.1}Topologie sieci}{18}
\contentsline {subsection}{\numberline {2.3.2}Wielowarstwowa sie\'c neuronowa jako uniwersalny aproksymator}{19}
\contentsline {subsection}{\numberline {2.3.3}Algorytm wstecznej propagacji}{19}
\contentsline {subsection}{\numberline {2.3.4}Interpretacja probabilistyczna sieci neuronowych}{21}
\contentsline {subsection}{\numberline {2.3.5}Regularyzacja sieci neuronowych}{22}
\contentsline {subsubsection}{Kara zwi\k azana z $\delimiter 69645069 \Theta \delimiter 86422285 _{2}$}{23}
\contentsline {subsubsection}{Kara zwi\k azana z $\delimiter 69645069 \Theta \delimiter 86422285 _{1}$}{23}
\contentsline {subsection}{\numberline {2.3.6}Czym r\'o\.zni\k a si\k e powy\.zsze kary?}{23}
\contentsline {subsection}{\numberline {2.3.7}Intuicje dotycz\k ace warstw sieci neuronowych}{24}
\contentsline {subsection}{\numberline {2.3.8}Reprezentacja rozproszona}{24}
\contentsline {subsubsection}{G\IeC {\l }\k eboka hierarchiczna struktura przyczyn\k a sukcesu algorytm\'ow z rodziny Deep Learning}{25}
\contentsline {chapter}{\numberline {3}Rozw\'oj metod uczenia}{27}
\contentsline {section}{\numberline {3.1}Sieci konwolucyjne oraz LeNet}{27}
\contentsline {subsection}{\numberline {3.1.1}Inwariancja}{27}
\contentsline {subsection}{\numberline {3.1.2}Sieci konwolucyjne}{28}
\contentsline {subsection}{\numberline {3.1.3}Pooling}{29}
\contentsline {subsection}{\numberline {3.1.4}LeNet}{29}
\contentsline {section}{\numberline {3.2}Autoenkodery, sie\'c Hintona i Salakhudinowa}{29}
\contentsline {section}{\numberline {3.3}Sie\'c Kryzhevskiego}{29}
\contentsline {section}{\numberline {3.4}GoogLeNet}{29}
\contentsline {section}{\numberline {3.5}Inne sieci}{29}
\contentsline {chapter}{\numberline {4}Moja implementacja}{31}
\contentsline {chapter}{Bibliografia}{33}
