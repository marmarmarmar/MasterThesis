\select@language {polish}
\contentsline {chapter}{\numberline {1}Historia}{7}
\contentsline {section}{\numberline {1.1}Pocz\k atki i perceptron}{7}
\contentsline {section}{\numberline {1.2}Zima sztucznej inteligencji}{7}
\contentsline {section}{\numberline {1.3}Dlaczego perceptron zawi\'od\IeC {\l }?}{8}
\contentsline {section}{\numberline {1.4}Algorytm wstecznej propagacji - odrodzenie i ponowna zima}{8}
\contentsline {section}{\numberline {1.5}Dlaczego sieci ponownie zawiod\IeC {\l }y?}{9}
\contentsline {chapter}{\numberline {2}Matematyczne podstawy algorytm\'ow}{11}
\contentsline {section}{\numberline {2.1}Uczenie}{11}
\contentsline {subsection}{\numberline {2.1.1}Formalna definicja uczenia}{11}
\contentsline {subsection}{\numberline {2.1.2}Uczenie z nadzorem}{12}
\contentsline {subsection}{\numberline {2.1.3}Uczenie bez nadzoru}{13}
\contentsline {subsection}{\numberline {2.1.4}Generalizacja oraz przeuczenie}{14}
\contentsline {subsubsection}{Zbiory walidacyjne i testowe}{15}
\contentsline {subsubsection}{Walidacja krzy\.zowa (ang. \textit {cross-validation})}{15}
\contentsline {subsection}{\numberline {2.1.5}Optymalizacja gradientowa}{16}
\contentsline {subsubsection}{Redukcja sta\IeC {\l }ej uczenia w wypadku wysokiej i sta\IeC {\l }ej warto\'sci funkcji kosztu (ang. \textit {learning rate reduction on plateau})}{17}
\contentsline {subsection}{\numberline {2.1.6}Stochastyczna optymalizacja gradientowa}{17}
\contentsline {subsection}{\numberline {2.1.7}Metaoptymalizacja}{18}
\contentsline {section}{\numberline {2.2}Sztuczne Sieci neuronowe}{18}
\contentsline {subsection}{\numberline {2.2.1}Biologiczna motywacja}{19}
\contentsline {subsection}{\numberline {2.2.2}Regresja logistyczna}{19}
\contentsline {subsubsection}{Sigmoidalna funkcja aktywacji}{19}
\contentsline {subsubsection}{Logistyczna funkcja kosztu - (ang. \textit {log-loss})}{20}
\contentsline {subsubsection}{Uog\'olnienie funkcji \textit {log-loss} do zagadnienia multiklasyfikacji}{20}
\contentsline {subsubsection}{Uog\'olnienie powy\.zszych funkcji kosztu do dowolnego modelu}{21}
\contentsline {section}{\numberline {2.3}Klasyczne sieci neuronowe oraz algorytm wstecznej propagacji}{21}
\contentsline {subsection}{\numberline {2.3.1}Topologie sieci}{21}
\contentsline {subsection}{\numberline {2.3.2}Wielowarstwowa sie\'c neuronowa jako uniwersalny aproksymator}{22}
\contentsline {subsection}{\numberline {2.3.3}Algorytm wstecznej propagacji}{23}
\contentsline {subsubsection}{Zjawisko przesuni\k ecia kowariancji (ang. \textit {covariate shift}) i technika normalizacji porcjowej (ang. \textit {Batch Normalization})}{24}
\contentsline {subsection}{\numberline {2.3.4}Interpretacja probabilistyczna sieci neuronowych}{25}
\contentsline {subsection}{\numberline {2.3.5}Regularyzacja sieci neuronowych}{26}
\contentsline {subsubsection}{Kara zwi\k azana z $\delimiter 69645069 \Theta \delimiter 86422285 _{2}$}{27}
\contentsline {subsubsection}{Kara zwi\k azana z $\delimiter 69645069 \Theta \delimiter 86422285 _{1}$}{27}
\contentsline {subsection}{\numberline {2.3.6}Czym r\'o\.zni\k a si\k e powy\.zsze kary?}{28}
\contentsline {subsection}{\numberline {2.3.7}Intuicje dotycz\k ace warstw sieci neuronowych}{28}
\contentsline {subsection}{\numberline {2.3.8}Reprezentacja rozproszona}{29}
\contentsline {subsubsection}{G\IeC {\l }\k eboka hierarchiczna struktura przyczyn\k a sukcesu algorytm\'ow z rodziny Deep Learning}{29}
\contentsline {chapter}{\numberline {3}Sieci konwolucyjne}{31}
\contentsline {section}{\numberline {3.1}Inwariancja}{31}
\contentsline {section}{\numberline {3.2}Architektura sieci konwolucyjnych}{32}
\contentsline {subsection}{\numberline {3.2.1}Najpopularniejsze rzutowania}{33}
\contentsline {subsection}{\numberline {3.2.2}Pooling}{34}
\contentsline {subsubsection}{Pooling globalny}{34}
\contentsline {section}{\numberline {3.3}Przegl\k ad najpopularniejszych architektur konwolucyjnych}{35}
\contentsline {subsection}{\numberline {3.3.1}Pierwsze sieci konwolucyjne}{35}
\contentsline {subsection}{\numberline {3.3.2}AlexNet}{35}
\contentsline {subsection}{\numberline {3.3.3}VGG}{35}
\contentsline {subsection}{\numberline {3.3.4}AlexNet}{35}
\contentsline {section}{\numberline {3.4}Przyk\IeC {\l }ad sieci neuronowej - ResNet}{35}
\contentsline {subsection}{\numberline {3.4.1}Po\IeC {\l }\k aczenia residualne}{35}
\contentsline {subsection}{\numberline {3.4.2}\IeC {\L }odyga sieci}{35}
\contentsline {subsection}{\numberline {3.4.3}Klasyfikatory pomocnicze}{35}
\contentsline {chapter}{Bibliografia}{37}
