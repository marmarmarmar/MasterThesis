\relax 
\catcode `"\active 
\select@language{polish}
\@writefile{toc}{\select@language{polish}}
\@writefile{lof}{\select@language{polish}}
\@writefile{lot}{\select@language{polish}}
\citation{twarze}
\citation{znaki}
\citation{mnist}
\citation{perceptron}
\citation{mccul-pitts}
\citation{minsky-papert}
\citation{minsky-papert}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Historia}{7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Pocz\k atki i perceptron}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Zima sztucznej inteligencji}{7}}
\citation{backprop}
\citation{conv }
\citation{recurrent}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Dlaczego perceptron zawi\'od\IeC {\l }?}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Algorytm wstecznej propagacji - odrodzenie i ponowna zima}{8}}
\citation{cybenko}
\citation{hornik}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Dlaczego sieci ponownie zawiod\IeC {\l }y?}{9}}
\citation{popper}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Matematyczne podstawy algorytm\'ow}{11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Uczenie}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Formalna definicja uczenia}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Uczenie z nadzorem}{12}}
\citation{TODO}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Uczenie bez nadzoru}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Generalizacja oraz przeuczenie}{13}}
\citation{TODO}
\citation{adagrad}
\citation{minibatch}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Optymalizacja gradientowa}{14}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Uproszczony schemat optymalizacji gradientowej}}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}Stochastyczna optymalizacja gradientowa}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Sztuczne Sieci neuronowe}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Biologiczna motywacja}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Perceptron}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Czym jest perceptron?}{15}}
\citation{logistyka}
\citation{TODO}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Wykres funkcji sigmoidalnej.}}{16}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoidalna funkcja aktywacji}{16}}
\@writefile{toc}{\contentsline {subsubsection}{Klasyfikacja przy u\.zyciu perceptronu.}{17}}
\@writefile{toc}{\contentsline {subsubsection}{Algorytm uczenia perceptronu.}{17}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Uproszczony algorytm uczenia perceptronu.}}{17}}
\citation{TODO}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Przyk\IeC {\l }ad architektury wartstwowej sieci typu \textit  {feed-forward}. Sie\'c o tej architekturze jest w stanie nauczy\'c si\k e logicznej funkcji XOR.}}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Klasyczne sieci neuronowe oraz algorytm wstecznej propagacji}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Topologie sieci}{18}}
\citation{aprox}
\citation{aprox2}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Przyk\IeC {\l }ad architektury rekurencyjnej. Zwr\'o\'cmy uwag\k e na skierowany cykl w grafie po\IeC {\l }\k acze\'n.}}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Wielowarstwowa sie\'c neuronowa jako uniwersalny aproksymator}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Algorytm wstecznej propagacji}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Rysunek pomocniczy dla procesu wstecznej propagacji.}}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Interpretacja probabilistyczna sieci neuronowych}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Regularyzacja sieci neuronowych}{22}}
\citation{lasso}
\@writefile{toc}{\contentsline {subsubsection}{Kara zwi\k azana z $\delimiter 69645069 \Theta \delimiter 86422285 _{2}$}{23}}
\@writefile{toc}{\contentsline {subsubsection}{Kara zwi\k azana z $\delimiter 69645069 \Theta \delimiter 86422285 _{1}$}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Czym r\'o\.zni\k a si\k e powy\.zsze kary?}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.7}Intuicje dotycz\k ace warstw sieci neuronowych}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.8}Reprezentacja rozproszona}{24}}
\citation{deeprep}
\citation{badania}
\@writefile{toc}{\contentsline {subsubsection}{G\IeC {\l }\k eboka hierarchiczna struktura przyczyn\k a sukcesu algorytm\'ow z rodziny Deep Learning}{25}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Rozw\'oj metod uczenia}{27}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Sieci konwolucyjne oraz LeNet}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Inwariancja}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Sieci konwolucyjne}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Pooling}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}LeNet}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Autoenkodery, sie\'c Hintona i Salakhudinowa}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Sie\'c Kryzhevskiego}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}GoogLeNet}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Inne sieci}{29}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Moja implementacja}{31}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibcite{twarze}{1}
\bibcite{znaki}{2}
\bibcite{mnist}{3}
\bibcite{perceptron}{4}
\bibcite{mccul-pitts}{5}
\bibcite{minsky-papert}{6}
\bibcite{backprop}{7}
\bibcite{conv}{8}
\bibcite{popper}{9}
\@writefile{toc}{\contentsline {chapter}{Bibliografia}{33}}
