\documentclass{pracamgr}

\usepackage[latin2]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english,polish]{babel}
\usepackage{polski}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage[boxed, onelanguage]{algorithm2e}


\author{Marcin Mo¿ejko}
\nralbumu{262793}
\title{Podstawy metod g³êbokiego uczenia wraz z przyk³adami zastosowañ}

\tytulang{Foundations of deep learning methods with examples of applications}

\kierunek{Matematyka}

% informatyka - nie okreslamy zakresu (opcja zakomentowana)
% matematyka - zakres moze pozostac nieokreslony,
% a jesli ma byc okreslony dla pracy mgr,
% to przyjmuje jedna z wartosci:
% {metod matematycznych w finansach}
% {metod matematycznych w ubezpieczeniach}
% {matematyki stosowanej}
% {nauczania matematyki}
% Dla pracy licencjackiej mamy natomiast
% mozliwosc wpisania takiej wartosci zakresu:
% {Jednoczesnych Studiow Ekonomiczno--Matematycznych}

% \zakres{Tu wpisac, jesli trzeba, jedna z opcji podanych wyzej}

% Praca wykonana pod kierunkiem:
% (podaæ tytu³/stopieñ imiê i nazwisko opiekuna
% Instytut
% ew. Wydzia³ ew. Uczelnia (je¿eli nie MIM UW))
\opiekun{Dr Ewy Szczurek}

% miesi±c i~rok:
\date{Wrzesieñ 2017}

%Podaæ dziedzinê wg klasyfikacji Socrates-Erasmus:
\dziedzina{ 
11.4 Sztuczna inteligencja\\ 
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{97-XX Mathematics education,\\
  97RXX 		Computer science applications\\
  97R40   	Artificial intelligence}

% S³owa kluczowe:
\keywords{deep learning, machine learning, uczenie maszynowe, sztuczne sieci neuronowe, 
sieci konwolucyjne}

% Tu jest dobre miejsce na Twoje w³asne makra i~¶rodowiska:
\newtheorem{defi}{Definicja}[section]
\newtheorem{przyklad}{Przyk³ad}[section]
\newtheorem{uwaga}{Uwaga}[section]
\newtheorem{twierdzenie}{Twierdzenie}[section]

% koniec definicji

\begin{document}
\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
W ostatnim czasie, w¶ród specjalistów zajmuj±cych siê uczeniem maszynowym, bardzo eksplorowanym tematem sta³o siê tzw. g³êbokie uczenie, czyli uczenie z wykorzystaniem g³êbokich (tzn. maj±cych wiele warstw) sieci neuronowych. W swojej pracy przedstawie matematyczne podstawy sukcesu stoj±cych za tym algorytmów.
\end{abstract}

\tableofcontents
	%\listoffigures
%\listoftables

\chapter*{Wprowadzenie}

W ostatnim czasie, jednym z tematów które najbardziej poch³aniaj± specjalistów od \textit{Machine Learningu} sta³y siê tzw. metody g³êbokiego uczenia (\textit{deep learning}). Co chwila mo¿emy us³yszeæ informacjê, ¿e wed³ug naukowców wykorzystuj±cych te metody, algorytmy przez nich otrzymane pokona³y cz³owieka w zagadnieniu, które do tej pory wydawa³o siê byæ tylko w zasiêgu ludzkiego umys³u \cite{twarze, znaki}. To co ³±czy wiêkszo¶æ tych zagadnieñ i jest w mojej opinii kluczowe do zrozumienia fenomenu \textit{deep learningu} to :

\begin{itemize}
	\item ogromna ilo¶æ danych (czêsto bez ¿adnych etykiet),
	\item du¿a problematyczno¶æ w zakodowaniu problemu w klasycznym jêzyku algorytmicznym,
	\item zbiór interesuj±cych nas danych jest niezwykle ma³y w stosunku do przestrzeni z której pochodz± dane.
\end{itemize}

Spróbujmy przyjrzeæ siê tym podpunktom. Rozwa¿aj±c np. problem rozpoznawania przedmiotów na filmach, mo¿emy natrafiæ na ciekawy symptom. Dziêki wieloletniej historii zapisu cyfrowej, przez lata ludzko¶æ zebra³a na rozmaitych no¶nikach danych niezmierzone ilo¶ci danych z kamer. Dziêki temu wspó³cze¶ni badacze maj± u³atwione zadanie przy budowaniu algorytmów do rozpoznawania filmów - mog± wykorzystaæ tak zdobyta wiedzê do poprawienia rezultatów uzyskiwanych przez ich programy.

Kolejny podpunkt, czyli problematyczno¶æ, mo¿emy doskonale zobrazowaæ przez przyk³ad zaprojektowania sieci rozpoznaj±cej czy dana recenzja na portalu spo³eczno¶ciowym zawiera pozytywn± opiniê o temacie b±d¼ nie. Niech czytelnik pokusi siê o zapisanie na kartce rzeczy, które algorytm powinien sprawdziæ aby uzyskaæ poprawn± odpowied¼. Krótka inspekcja powinna u¶wiadomiæ jak karko³omne zadanie staje przed badaczami, którzy siê tym zajmuj±. Wyniki ostatnich algorytmów pokazuj± jednak, ¿e problem ten nie przekracza zasiegu wspó³czesnych technologii \cite{sentiment}.

Ostatnie zagadnienie - najlepiej zobrazowaæ liczbami. Za³ó¿my, ¿e rozwa¿amy obraz który posiada 28 x 28 pikseli oraz, dla uproszczenia, jest czarnobia³y. Ilo¶æ wszystkich mo¿liwych obrazków tego typu przekracza niewyobra¿alnie liczbê atomów we wszech¶wiecie. Natomiast liczba obrazków które prezentuj± nam co¶ interesuj±cego (np. znany problem rozpoznawania cyfr \cite{mnist}) jest liczb± zdecydowanie mniejsz±. Mo¿na powiedzieæ, ¿e interesuj±cy nas zbiór jest niczym galaktyka po¶ród otaczaj±cego j± szumu i pustki.

W swojej pracy chcia³bym przedstawiæ w jaki sposób poradzono sobie z powy¿szymi zagadnieniami. Zamierzam zacz±æ od historii powstania tych algorytmów, któr± uwa¿am za bardzo wa¿n± w zrozumieniu istoty ich dzia³ania, by potem zg³êbiæ podstawy matematycznych narzêdzi stoj±cych za sukcesem \textit{deep learningu}. W kolejnych rozmiarach zamierzam, na podstawie historycznych algorytmów, przedstawiæ to, co stanowi esencjê sukcesu metod g³êbokiego uczenia. Wydajê mi siê, ¿e ta droga wyt³umaczy najlepiej, dlaczego niemal ka¿dy szanuj±cy siê o¶rodek naukowy posiada dzi¶ grupê zajmuj±c± siê metodami g³êbokiego uczenia.

Zwieñczeniem pracy bêdzie implementacja g³êbokiej sieci neuronowej przeznaczonej do rozpoznawania komórek guza raka jelita grubego. Osi±gniête rezultaty poprawiaj± aktualnie najlepsze na ¶wiecie wyniki w tej dziedzinie o ponad $4\%$. Co wiêcej - rezultaty te wskazuj± na to, ¿e istnieje mo¿liwo¶æ dalszej poprawy wyników oraz rozszerzenia u¿ywania przedstawionej architektury do innych zastosowañ z zakresu analizy medycznej zdjêæ.

\chapter{Historia}

\section{Pocz±tki i perceptron}

Aby dobrze zrozumieæ historiê metod \textit{deep learning} nale¿y choæ pobie¿nie zg³êbiæ historiê powstania i rozwoju metod opartych na tym paradygmacie. Mo¿na powiedzieæ, ¿e historia ta zaczê³a siê w momencie odkrycia przez biologów neuronalnej natury mózgu, jednak pocz±tki algorytmicznych sieci neuronowych, których najwy¿sz± emanacj± s± g³êbokie sieci, datuje siê na koniec lat 60' XX w., gdy Frank Rosenblat przygotowa³ mechaniczno - elektryczny perceptron \cite{perceptron}, czyli realizacje modelu neuronu McCullocha-Pittsa \cite{mccul-pitts}. Choæ teoretyczne podstawy opracowane przez wspomniany duet naukowców powsta³y ponad 25 lat wcze¶niej, to rewolucyjnym rozwi±zaniem, zastosowanym w przypadku koncepcji Rosenblata by³ efektywny i skuteczny model uczenia, który przyczyni³ siê do wieloletniego, bujnego rozwoju zastosowañ opartych na tej koncepcji. Warto tutaj podkre¶liæ motyw, który bêdzie powtarza³ siê przy omawaniu kolejnych punktów, biologiczne inspiracje, które doprowadzi³y do rozwoju algorytmicznych rozwi±zañ.

\section{Zima sztucznej inteligencji}

I wtedy, gdy wydawa³o siê, ¿e perceptron to narzêdzie niemal idealne do wszystkich zadañ, na horyzoncie pojawi³ siê ogromny problem. Jako narzêdzie, wynalazek Rosenblata s³u¿y³ m.in. do rozpoznawania obiektów na obrazach. Okaza³o siê jednak, ¿e mniemanie o jego  skuteczno¶ci jest znacznie przesadzone. W wiêkszo¶ci wypadków bowiem okaza³o siê, ¿e to co zostaje wykrywane to jaka¶ prosta cecha, która towarzyszy obrazom interesuj±cym badaczy, a nie obiektom obecno¶æ których algorytm mia³ wykrywaæ. I tak zamiast statków algorytm wykrywa³ ciemne plamy po ¶rodku zdjêcia, a zamiast czo³gów - zaciemnienia w kszta³cie lasu, w których najczê¶ciej maszyny by³y fotografowane \cite{minsky-papert}. Co wiêcej, w Marvin Minsky oraz Seymour Papert \cite{minsky-papert} pokazali du¿o mocniejsze ograniczenia na to, co mog³o byæ efektywnie rozpoznane przez perceptron. Okaza³o siê, ¿e wyuczenie prostej, logicznej funkcji XOR przekracza mo¿liwo¶ci wynalazku Rosenblata. Co wiêcej - uogólnienie tego wyniku pokaza³o, ¿e w szczególno¶ci, niezale¿enie od rozmiaru oraz typu zbioru treningowego, nie mo¿na perceptronu nauczyæ rozpoznawania wzoru, który by³by zamkniêty na wszystkie mo¿liwe translacje (przesuniêcia) na obrazku. Fakt ten, wywo³a³ tak ogromny szok, ¿e ilo¶æ naukowców oraz funduszy przeznaczonych na badania drastycznie zmala³a, a niski poziom zainteresowania utrzymywa³ siê przez kolejne 10 lat. Dlatego w³a¶nie lata 70' XX wieku ten nazywa siê w historii \textit{machine learningu} zim± sztucznej inteligencji.

\section{Dlaczego perceptron zawiód³?}

Odpowied¼ na pytanie dlaczego perceptron zawiód³, nale¿y podzieliæ na dwa fragmenty : jakie by³y matematyczne powody dla których algorytm nie podo³a³ oczekiwaniom oraz dlaczego oczekiwania które zawiód³ by³y tak ogromne. Odpowied¼ na pierwsz± czê¶æ jest prozaiczna. Model McCullocha-Pittsa zastosowany przez Rosenblata, ogranicza dzia³anie algorytmu do rozwa¿ania znaku jaki przyjmuje funkcjona³ afiniczny dla zadanego wektora w $\mathbb{R}^n$. Krótka inspekcja tego faktu pokazuje, ¿e istotnie rozró¿niane wedle tego algorytmu mog± byæ tylko zbiory, które s± separowalne liniowo, tzn. istnieje podprzestrzeñ kowymiaru 1, która je istotnie oddziela. Odpowiedzi na drug± czê¶æ, czyli spo³eczne rozczarowanie, które poci±gn±³ za sob± krach zaufania do perceptronu nadal trudno udzieliæ. Byæ mo¿e wynika³o to z ogólnego wówczas zachwytu nad nowymi technologiami spowodowanego wynalezieniem komputerów i powszechnych sukcesów elektroniki? \cite{lem} Z ca³± pewno¶ci± po latach - patrz±c na matematyczne podstawy algorytmu Rosenblata - mo¿emy stwierdziæ, ¿e nadmierne oczekiwania w stosunku do tak prostego narzêdzia okaza³y siê po prostu naiwne. Co wiêcej - naiwno¶æ ta nie le¿y tylko w matematycznej podstawie algorytmu, ale tak¿e w biologicznej nieadekwatno¶ci: skoro naukowcy powo³ywali siê czê¶ciowo na na¶ladowanie mózgu to nie sposób dostrzec prostego faktu, ¿e organ ten u cz³owieka posiada ok. $10^{11}$ neuronów i z tyle razy mniejszej liczby sk³ada siê perceptron. 

\section{Algorytm wstecznej propagacji - odrodzenie i ponowna zima}

Przez kolejne lata badacze rozwijaj±cy algorytmy zwi±zane z sieciami neuronowymi próbowali pokonaæ przedstawione powy¿ej przeszkody. Naturalnym rozwi±zaniem wydawa³o siê zbudowanie sieci sk³adaj±ce siê z wiêkszej ilo¶ci - tak neuronów, jak i ich warstw. Rozwi±zanie to napotka³o jednak na dosyæ powa¿ny problem - o ile uczenie perceptronu by³o zadaniem banalnie prostym, to wyuczenie sieci o wiêkszej ilo¶ci wartstw okaza³o siê zadaniem o wiele trudniejszym. Podstawowy problem wynika z tego, ¿e aby otrzymaæ now± jako¶æ i przezwyciê¿yæ stare problemy, nale¿y zastosowaæ inn± ni¿ liniow± funkcjê obliczaj±c± wynik neuronu w zale¿no¶ci od informacji której do niego wprowadzimy. Konieczno¶æ ta wyp³ywa ze znanego faktu, ¿e z³o¿enie wielu funkcji liniowych, jest tak¿e funkcj± liniow±. Zatem niezale¿enie od tego ile neuronów bêdzie sk³ada³o siê na strukturê naszej sieci - uzyskane narzêdzie bêdzie równowa¿ne klasycznemu perceptronowi. 

Jednak wprowadzenie nieliniowych tzw. funkcji aktywacji rodzi inne problemy - jak mianowicie skutecznie przeprowadziæ proces uczenia naszego modelu gdy analityczne rozwi±zania na ogó³ s± nieosi±galne? I tutaj pomoc przysz³a z najmniej spodziewanej strony, a mianowicie pochodz±cej z klasycznego rachunku ca³kowego regu³y ³añcuchowej (wzoru na pochodn± z³o¿enia funkcji). Algorytm, (Rumelhart et al. \cite{backprop}) którego istota dzia³ania polega na obliczeniach gradientu b³êdu, a nastêpnie aktualizowania odpowiednich parametrów na podstawie ich wp³ywu na omylno¶æ modelu (wp³yw ten jest oblicznany w³a¶nie przez regu³ê ³añcuchow±) przyniós³ fantastyczne rezultaty. Ze wzglêdu na to, ¿e b³±d obliczany przy dzia³aniu sieci, propaguje siê nastêpnie na odpowiednie parametry, nazwano go algorytmem wstecznej propagacji.

Od momentu prezentacji algorytmu (1986 r.) nast±pi³ ponowny, bujny rozwój sieci neuronowych, który zaowocowa³ powstaniem wielu technik, które s± popularne do dzi¶ (np. \cite{backprop, recurrent}). Co jednak charakterystyczne, entuzjazm towarzysz±cy badaniom stanowi³ tylko cieñ euforii która towarzyszy³a wynalezieniu perceptronu. Po oko³o 10 latach (pocz±tek lat 90' XXw.), z powodu zbyt wolnego rozwoju technologii i algorytmów, a tak¿e nieuzyskiwania oczekiwanych rezultatów, przyszed³ czas ponownego rozczarowania, podczas którego niemal skre¶lono sieci neuronowe z listy obiecuj±cych kierunków rozwoju \cite{vapnik-bet}. Traktowano je bardziej jako wzorowan± na przyrodzie ciekawostkê, ni¿ algorytm który mo¿e przynie¶æ rozwi±zanie dla podstawowych problemów sztucznej inteligencji.

\section{Dlaczego sieci ponownie zawiod³y?}

Ponowna zima jednak, podobnie jak i entuzjazm który towarzyszy³ powrotowi sieci neuronowych do ³ask, okaza³a siê du¿o mniej intensywna ni¿ poprzednia. Spróbujmy jednak przyjrzeæ siê podstawowym przyczynom, które sprawi³y, ¿e modele te zawiod³y oczekiwania rozwijaj±cych je badaczy.

Pierwsz± przyczyn± stanowi³y ponownie zbyt du¿e oczekiwania. Jakkolwiek na prze³omie lat 90' XX w. udowodniono, ¿e sieæ z jedn± tzw. warstw± ukryt± jest w stanie nauczyæ siê niemal ka¿dej funkcji $f:\mathbb{R}^n\rightarrow \mathbb{R}$ ci±g³ej o zwartym no¶niku \cite{cybenko, hornik}, to nie do koñca zdawano sobie sprawe, ¿e zadania nauczenia chocia¿by rozpoznawania obrazu lub ludzkiej mowy, choæ mo¿liwe, mog± byæ bardzo trudne. W szczególno¶ci, w dowodach powy¿szego faktu, niedostrze¿ono alarmuj±cego wzrostu z³o¿ono¶ci problemu wraz ze wzrostem jego skomplikowania. Efektywne uczenie oparte na metodzie przedstawionej dowodach aproksymowalno¶ci wymaga albowiem ekspotencjalnego wzrostu w ilo¶ci wymaganych przyk³adów treningowych.

Drug± przyczynê, zwi±zan± w³a¶nie ze wspomnianym powy¿ej problemem, stanowi³y niedostateczne warunki sprzêtowe, które uniemo¿liwia³y wykorzystanie potencja³u drzemi±cego w algorytmie. Niedostateczno¶æ ta nie wynika³a tylko ze zbyt ma³ych mo¿liwo¶ci obliczeniowych, ale tak¿e znacznego niedoboru danych (tak w sensie ich zebrania, jak i przechowywania). Najwiêksze zebrane zbiory treningowe nie liczy³y, na pocz±tku lat 90', wiêcej ni¿ 100 000 elementów. Z perspektywy wyuczenia chocia¿by zagadnieñ zwi±zanych z obrazem lub mow± ludzk± liczba ta jawi siê jako niemal¿e ¶miesznie ma³a. Problemy te jednak rozwi±za³ czas - wraz z rozwojem technologii pojawi³y siê tak i nowoczesne komputery, które przyspieszy³y proces uczenia oraz ewaluacji, jak i ogromne, zró¿nicowane zbiory danych, które sprawi³y, ¿e problemy o rozwi±zaniu których marzyli eksperci od sztucznej inteligencji, znalaz³y siê jak najbardziej w zasiêgu ludzkich mo¿liwo¶ci.

\chapter{Matematyczne podstawy algorytmów} \label{matpod}

\section{Uczenie}

Wszystkie algorytmy opisane w tej pracy nale¿± do rodziny algorytmów ucz±cych. Aby móc o nich mówiæ musimy zatem wprowadziæ formaln± definicjê uczenia. Zrobimy to w kolejnej podsekcji. Pó¼niej przedstawimy trzy najczêstsze przyk³ady uczenia czyli uczenie z i bez nadzoru, a tak¿e uczenie z pó³nadzorem. 

\subsection{Formalna definicja uczenia} \label{defucz}

Trzy rzeczy s± absolutnie niezbêdne aby mówiæ o o algorytmach ucz±cych. Pierwsza z nich to zbiór treningowy $\mathcal{X}$. Nale¿y o nim my¶leæ jako o zbiorze danych, które znamy, a które chcemy wykorzystaæ jako podstawê do uczenia przy pomocy naszego algorytmu. Drug± z nich jest zbiór modeli. Efektem uczenia ma byæ efektywnie opisuj±cy nasze dane model, aby jednak móc taki znale¼æ, musimy ustaliæ pewien zbiór mo¿liwych modeli spo¶ród którego bêdziemy go wybieraæ. Koniecznym jest tak¿e ustalenie, co oznacza, ¿e nasze dane s± efektywnie opisywane przez wybrany przez nas opis - do tego s³u¿y funkcja kosztu. Intuicyjnie, funkcj± kosztu nazywamy nieujemn± funkcjê rzeczywist±, malej±c± wraz ze wzrostem efektywno¶ci opisywanych danych ze zbioru treningowego $\mathcal{X}$. Wszystkie powy¿sze intuicje sk³adaj± siê na poni¿sz± definicjê. 

\begin{defi}
Niech $\mathcal{X}$ bêdzie dowolnym zbiorem (tzw. \textbf{treningowym}), $\Theta$ - zbiorem modeli, a 
$$J_{\mathcal{X}} : \Theta \rightarrow \mathbb{R}_{+}\cup \{0\}$$ funkcj± kosztu. \textbf{Uczeniem} bêdziemy nazywaæ algorytm maj±cy na celu odnalezienie :

$$ \theta_{\mathcal{X}} = \mathtt{argmin}_{\theta \in \Theta} J_{\mathcal{X}}\left(\theta\right).$$

\end{defi}

Przy okazji tej definicji nale¿y podnie¶æ kilka istotnych kwestii, które s± ¶ci¶le zwi±zane z procesem uczenia, a które nale¿± do zagadnieñ filozofii nauki i przekraczaj± zakres poni¿szej pracy. Pierwsz± rzecz± na któr± nale¿y zwróciæ uwagê jest to, ¿e $\theta_{\mathcal{X}}$ to \textit{de facto} rozwi±zanie pewnego problemu optymalizacyjnego i nie nale¿y do gestii algorytmu ucz±cego rozs±dzanie czy opis wyznaczany przez wybrany model mie¶ci siê w granicach które uznajemy za rozs±dne, b±d¼ nie. Wybór rodziny modeli, a tak¿e funkcji kosztu musi poprzedziæ g³êboka analiza, a tak¿e refleksja nad problemem, aby dokonany przez nas wybór nie okaza³ siê niesatysfakcjonuj±cy. Nale¿y mieæ tak¿e w pamiêci, ¿e zgodnie z aktualnie przyjêt± filozofi± \cite{popper}, wybrany przez nas model, nawet w kontek¶cie uzyskania pozytywnych wyników, nale¿y traktowaæ jako niesfalsyfikowany, a nie prawdziwy. Jest to o tyle istotne, ¿e wypracowane przez nas rozwi±zanie zale¿y w bardzo istotny sposób od zbioru danych, który wykorzystujemy przy uczeniu - nap³yw kolejnych, mo¿e doprowadziæ do weryfikacji tak konkrentego $\theta_{\mathcal{X}}$ jak i samej rodziny $\Theta$.

\subsection{Uczenie z nadzorem}

Przez uczenie z nadzorem rozumiemy przypadek, w którym mo¿emy wyró¿niæ dwa zbiory $\mathbb{X}_\mathcal{X}$ (zbiór argumentów) oraz $\mathbb{Y}_\mathcal{X}$ (zbiór warto¶ci) takie, ¿e $\mathcal{X} \subset 
\mathbb{X}_\mathcal{X} \times \mathbb{Y}_\mathcal{X}$. Oznacza to, ¿e na ka¿dy element zbioru treningowego mo¿emy patrzyæ jak na parê argument - warto¶æ, a rodzinê modeli $\Theta$ z których wybieramy okre¶liæ jako rodzinê funkcji najlepiej przybli¿aj±c± relacjê jak± na $\mathbb{X}_\mathcal{X} \times \mathbb{Y}_\mathcal{X}$ generuje zbiór $\mathcal{X}$. Dobr± ilustracjê do tego zagadnienia ilustruje poni¿szy przyk³ad.

\begin{przyklad}\label{mse}
W poni¿szym przyk³adzie za zbiór treningowy $\mathcal{X}$ uznamy punkty zaznaczone czarnymi okrêgami, przyjmuj±c, ¿e pierwsza wspó³rzêdna odpowiada argumentom, a druga - warto¶ciom. Funkcj± kosztu (tzw. b³êdem ¶redniokwadratowym) bêdzie funkcja :

$$J\left(\theta\right) = \sum_{x \in \mathbb{X}_\mathcal{X}}\left(y_x - f_{\theta}(x) \right)^2,$$

gdzie $y_x$ to warto¶æ odpowiadaj±ca argumentowi $x$, a $f_\theta$ to funkcja odpowiadaj±ca modelowi $\theta$. Na poni¿szym obrazku kolorem czerwonym oznaczono $\theta_\mathcal{X}$ w przypadku gdy $\Theta$ to zbiór funkcji liniowych, zielonym - gdy $\Theta$ to zbiór funkcji sze¶ciennych, natomiast niebieskiem - przypadek gdy $\Theta$ to zbiór funkcji wielomianowych stopnia co najwy¿ej 20. 	

\begin{center}
\includegraphics[scale = 0.5]{Regresja1.png}
\end{center}

\end{przyklad}

Warto podkre¶liæ, ¿e wybrana przeze mnie ogólno¶æ definicji ma swoje g³êbokie uzasadnienie. Zwyczajowo techniki uczenia z nadzorem dzieli siê na dwie grupy: techniki regresji (gdy $\mathbb{Y}_{\mathcal{X}} = \mathbb{R}^n$ dla pewnego $n\in\mathbb{N}$) oraz techniki klasyfikacji (gdy $\mathbb{Y}_{\mathcal{X}}$ jest zbiorem dyskretnym). W swoim opisie podkre¶lam jednak to, ¿e tym co \textit{de facto} jest szukane, to zale¿no¶æ funkcyjna, poniewa¿ pozwala nam to na znacznie szerszy dobór struktur warto¶ci (np. dopuszcza jako $\mathbb{Y}_{\mathcal{X}}$ chocia¿by zdañ w jêzyku angielskim).

\subsection{Uczenie bez nadzoru}

Przez uczenie bez nadzoru bêdziemy rozumieæ tak± formê uczenia, w której $\Theta$ jest zbiorem mo¿liwych, po¿ytecznych reprezentacji zbioru danych $\mathcal{X}$. Funkcja kosztu $J_{\mathcal{X}}$ okre¶la w tym przypadku jak efektywny opis danych gwarantuje nam model $\theta$. Czêsto zmiana reprezentacji danych stanowi konieczny krok przy analizie danych. Zauwa¿my np., ¿e z perspektywy komputera obraz z kamery telewizyjnej to ci±g elementów ze zbioru $\mathbb{R}^{6220800}$ (przy za³o¿eniu jako¶ci FullHd z kodowaniem RGB), co czyni problem komputerowej analizy takiego obrazu praktycznie nierozwi±zywalnym. Na poni¿szym przyk³adzie zobaczmy jak wygl±da dobór reprezentacji przy uczeniu bez nadzoru.

\begin{przyklad}

Poni¿ej przedstawimy przyk³ad tzw. uczenia rozmaito¶ci (\textit{manifold learning} \cite{manifold-learning}) metod± t-SNE. W przyk³adzie tym:
$$\mathcal{X} = \left\{x_1, x_2, \dots, x_k \right\} \subset \mathbb{R}^{n},$$
oraz
$$\Theta = \left\{\left\{\theta_1, \theta_2, \dots, \theta_k\right\}\!{:}\ \theta_1, \theta_2, \dots, \theta_k \in \mathbb{R}^{m}\right\}.$$

Aby zdefiniowaæ funkcjê b³êdu potrzebne bêd± nam pomocnicze wyra¿enia:

$$p_{j|i} = \frac{\exp\left(-||x_i - x_j||^2/2\sigma_i^2\right)}{\sum_{k\neq i}
\exp\left(-||x_i - x_k||^2/2\sigma_i^2\right)},$$

$$p_{ij} = \frac{p_{j|i} + p_{i|j}}{2},$$

$$q_{ij} = \frac{\left(1 + ||\theta_i - \theta_j||^2\right)^{-1}}{\sum_{k\neq l}\left(1 + ||\theta_k - \theta_l||^2\right)^{-1}},$$

gdzie $\sigma_i \in \mathbb{R}^2$ dla $i = 1, \dots n$ to ustalone wcze¶niej parametry. Ustalmy funkcjê kosztu:

$$J_{\theta} = \sum_{i \neq j} p_{ij}\log\frac{p_{ij}}{q_{ij}}.$$

Rozwi±zanie tego typu problemu mo¿emy uznaæ jako znalezienie odpowiedniej reprezentacji $\theta_i$ dla ka¿dego z punktów $x_i$, gdzie $i = 1, \dots, n$. Na poni¿szym obrazku (\figurename{ \ref{torus-tsne}}) prezentujemy przyk³adowe rozwi±zanie dla nastêpuj±cego zbioru :

$$\mathcal{X} = \left\{\left(\sin\alpha, \cos\alpha, sin\beta, \cos\beta\right): \alpha, \beta = 0, \frac{2\pi}{n}, \frac{4\pi}{n}, \dots, 2\pi\right\} \subset \mathbb{R}^4,$$

czyli czterowymiarowego zanurzenia torusa w wypadku gdy $m=3$, $n=50$ oraz 
$$\sigma_1, \sigma_2, \dots, \sigma_{2500} = 1.$$

\begin{figure}[b!]\label{torus-tsne}
\begin{center}
\includegraphics[scale = 0.5]{torus_tsne.png}
\caption{Na obrazku widaæ, ¿e \textit{p±czkowata} struktura torusa zosta³a uchwycona w trójwymiarowej reprezentacji zbioru $\mathcal{X}$. Potwierdza to efektywn± redukcjê wymiarowo¶ci gdy¿ 4-wymiarowe zanurzenie torusa zosta³o efektywnie przedstawione w $\mathbb{R}^3$.}
\end{center}
\end{figure}

\end{przyklad}

\subsection{Generalizacja oraz przeuczenie}

W dotychczasowych rozwa¿aniach przyjêli¶my, ¿e g³ównym celem uczenia jest odnalezienie modelu, który minimalizuje ustalon± przez nas funkcjê b³êdu. Jednak problem uczenia zawiera w sobie jeszcze jedn± p³aszczyznê. Zbiór posiadanych przez nas danych mo¿e siê rozszerzyæ o nowe punkty - i naturalnym jest oczekiwanie od modelu, ¿e funkcja b³êdu bêdzie przybiera³a porównywalne warto¶ci na rozszerzonym zbiorze. Tak± zdolno¶æ modelu nazywamy \textit{generalizacj±}.

Zjawisko przeciwne, tzn. stan w którym warto¶æ funkcji b³êdu wzrasta znacz±co po dodaniu nowych punktów nazywamy \textit{przeuczeniem}.

\begin{przyklad}
Jednym z ciekawszych sposobów sprawdzenia czy nasz model mo¿e do¶wiadczyæ zjawiska przeuczenia jest analiza wariancji modelów metod± tzw. resamplingu. Intuicyjnie - je¶li model ma uchwyciæ faktyczn± strukturê danych - to dla ró¿nych zbiorów danych pochodz±cych z tego samego ¼ród³a - modele zbudowane wedle tych zbiorów powinny byæ podobne. Du¿a wariancja w¶ród modeli mo¿e natomiast wskazywaæ na to, ¿e nasz model mo¿e do¶wiadczaæ zjawiska przeuczenia. Poni¿ej prezentujemy przyk³ad takiego sprawdzenia. Oryginalne dane pochodz± z wielomianu 4-go stopnia, którego wykres zaprezentowany jest w prawym górnym rogu obrazka. W kolejnych oknach prezentujemy ró¿ne modele wielomianowe wytrenowane na delikatnie zaburzonych danych podstawowych.  

\begin{center}
\includegraphics[scale = 0.37]{overfitting.png}
\end{center}

Widzimy, ¿e w przypadku wielomianów stopnia pierwszego mamy do czynienia z ma³± wariancj± modeli - jednakowo¿ - modele te odleg³e s± od dobrej aproksymacji wyj¶ciowej funkcji. W przypadku aproksymacji wielomianami stopnia 4 - zarówno jako¶æ aproksymacji oraz jednorodno¶æ modeli stoj± na wysokim poziomie. W wypadku aproksymacji modelami stopnia 16 - widzimy, ¿e zarówno jako¶æ aproksymacji oraz jednorodno¶æ modeli uleg³y znacz±cemu obni¿eniu. Modele tej rodziny mog± zatem zostaæ przeuczone na danym zbiorze danych.

\end{przyklad}

\subsubsection{Zbiory walidacyjne i testowe}

Czêstym i naturalnym przeznaczeniem modelu jest jego zastosowanie na nowych danych. Dlatego sprawdzenie czy wyniki uzyskiwane na przyk³adach pochodz±cych spoza zbioru treningowego s± porównywalne do tych uzyskiwanych na zbiorze testowym w wielu przypadkach stanowi kluczowy punkt w ocenie przydatno¶ci rozwi±zania. W celu zasymulowania nap³ywu nowych danych stosuje siê tzw. technikê \textit{zbioru testowego}, w której czê¶æ danych nie uczestniczy w dzia³aniu algorytmu optymalizacyjnego - lecz testuje aktualn± skuteczno¶æ modelu i pozwala np. zaobserwowaæ czy model dzia³a znacznie lepiej na przyk³adach treningowych ni¿ testowych (co jest zaprzeczeniem tego, ¿e model powinien dobrze radziæ sobie dla nowych danych).

Czêstym zjawiskiem jest tak¿e wyodrêbnianie jeszcze jednego zbioru - tzw. \textit{zbioru walidacyjnego}. Celem tego wyodrêbnienia jest unikniêcie sytuacji w której rozwijaj±cy rozwi±zanie wykorzystuj± informacjê ze zbioru testowego w trenowaniu. Wówczas nie jest uczciwym powiedzenie, ¿e zbiór testowy \textit{na¶laduje} nap³yw nowych danych. Dlatego ostateczny wynik walidowany jest na osobnym \textit{zbiorze walidacyjnym}, na którym rozwi±zanie u¿yte jest dok³adnie jeden raz i które wynik jest ostateczn± estymat± u¿yteczno¶ci rozwi±zania. 

\subsubsection{Walidacja krzy¿owa (ang. \textit{cross-validation})}

Wyra¿nymi wadami techniki \textit{zbiorów testowego-walidacyjnego} s± dwa nastêpuj±ce fakty:

\begin{itemize}
\item tylko niewielki procent posiadanych danych zostaje wykorzystany do symulowania nap³yniêcia nowych danych, co czyni estymatê skuteczno¶ci modelu mniej dok³adn±,
\item wynik modelu mo¿e zostaæ wyra¿nie zaburzony je¶li wydzielony do testowania zbiór bêdzie mia³ dystrybucje znacz±co ró¿n± od dystrybucji zbioru treningowego (tzw. szum podzia³u - ang. \textit{bias split}).

\end{itemize}

Aby unikn±æ tych dwóch niedogodno¶ci stosujê siê tzw. metodê \textit{$k$-walidacji krzy¿owej}, w której zbiór danych dzielony jest na $k$ róznych czê¶ci (ang. \textit{folds}), z których nastêpnie wybiera siê kolejne $k-1$ elementowe zbiory czê¶ci jako zbiory treningowe, a niewybran± czê¶æ wykorzystuje siê do walidowania uzyskanego modelu. Uzyskane w ten sposób $k$ wyników wykorzystuje siê do ostatecznej estymaty (najczê¶ciej badaj±c ich rozk³ad i bior±c ¶redni± wyników jako ostateczny wynik).

Dzieki tej metodzie ka¿dy element wyj¶ciowego zbioru danych uczestniczy w symulowaniu nap³ywu nowych danych, a zjawisko szumu podzia³u jest mniej szkodliwe, jako, ¿e wielokrotne jego powtórzenie jest zjawiskiem bardzo rzadkim. Wszystko to odbywa siê kosztem czasu uczenia - w zwi±zku z wielokrotnym uczeniem modelu technika ta wymaga znacznie wiêcej czasu ni¿ uczenie wykorzystuj±cy podzia³ na zbiory \textit{treningowy-testowy-walidacyjny}.

Warto dodaæ - ¿e ze zbioru treningowego czêsto wydziela siê osobny zbiór testowy, który uczestniczy w procesie uczenia w sposób opisany w poprzedniej subsekcji.


\subsection{Optymalizacja gradientowa}

Jak wspominali¶my w podsekcji \ref{defucz}, algorytmy uczenia to de facto algorytmy rozwi±zuj±ce pewne zadanie optymalizacyjne. Aktualnie tylko dla niewielkiej czê¶ci z nich potrafimy odnale¼æ rozwi±zanie w sposób ¶ci¶le analityczny. Dlatego dla du¿ej grupy problemów uczenia maszynowego stosuje siê tzw. metody optymalizacji gradientowej. Schemat dzia³ania wiêkszo¶ci z tych metod przybli¿a poni¿szy algorytm \cite{gradient-descents}.

\begin{algorithm}
  \KwData{Zbiór danych $\mathcal{X}$, rodzina modeli $\Theta$ parametryzowana przez argumenty $\theta_1, \theta_2, \dots, \theta_n$ oraz ró¿niczkowalna funkcja b³êdu $J_\mathcal{X}$.}
  \KwResult{Warto¶ci parametrów $\theta_1, \theta_2, \dots, \theta_n$ dla których rozwi±zanie jest mo¿liwie najlepsze ze wzglêdu na funkcjê kosztu $J_\mathcal{X}$.}
  zainicjuj wagi $\theta_1, \theta_2, \dots, \theta_n$ w sposób losowy. \;
  oblicz $J_{\mathcal{X}}\left(\theta_1, \theta_2, \dots, \theta_n\right)$\;  
  \While{$J_\mathcal{X}\left(\theta_1, \theta_2, \dots, \theta_n\right)$ nie spe³nia warunku stopu} {
    oblicz $\delta_i = \frac{\partial J_{\mathcal{X}}\left(\theta_1, \theta_2, \dots, \theta_n\right)}   {\partial \theta_i}$ dla ka¿dego $i = 1, \dots, n$\;    
    zaktualizuj: $\theta_{i} := \theta_i - \delta_i\eta$ dla ka¿dego $i = 1, \dots, n$\;
    ponownie oblicz $J_{\mathcal{X}}\left(\theta_1, \theta_2, \dots, \theta_n\right)$\;  
    } 
    \caption{Uproszczony schemat optymalizacji gradientowej}
\end{algorithm}

Oczywi¶cie powy¿szy schemat zosta³ uproszczony w celu uchwycenia g³ównej idei. Zgodnie z matematycznym faktem, który mówi, ¿e gradient wyznacza kierunek najwy¿szego wzrostu, pod±¿anie w kierunku przeciwnym do wyznaczonego przez niego jest to¿same pod±¿aniu w kierunku najwiêkszego spadku. 
Sta³a $\eta$, która pojawia siê w algorytmie nazywana jest \textit{sta³± uczenia} (ang. \textit{learning rate}) i powinna byæ dobierana ostro¿nie. W wielu algorytmach mo¿e ona zmieniaæ siê wraz z rosn±c± liczb± iteracji, a najskuteczniejsze aktualnie metody gradientowe ustalaj± j± nawet jako funkcjê wag oraz historii kolejnych iteracji \cite{adam, nadam}.
Warunek stopu wystêpuj±cy w warunku pêtli natomiast najczê¶ciej ustalany jest jako zej¶cie warto¶ci funkcji kosztu $J_\mathcal{X}$ poni¿ej pewnej ustalonej warto¶ci $\epsilon$ lub brak dostatecznej poprawy (wzglêdnej lub bezwzglêdnej) w stosunku do warto¶ci obliczonej w poprzedniej iteracji. 

Innym czêsto spotykanym schematem jest ustalenie pewnej du¿ej ilo¶ci operacji uczenia (zwanych czêsto \textit{epokami} - ang. \textit{epochs}) i brania jako ostatecznego modelu albo rozwi±zania uzyskanego po ostatniej epoce, albo rozwi±zania które uzyska³o najlepszy wynik na \textit{zbiorze testowym}.

\subsubsection{Losowa inicjalizacja}

Istotn± rzecz± jest losowa inicjalizacja parametrów sieci. Zainicjowanie ich warto¶ci jednakowym $x \in \mathbb{R}$ sprawia, ¿e gradienty ze wzglêdu na wszystkie jednostki s± identyczne (wszystkie \textit{neurony} s± nierozró¿nialne, przez co pochodne ze wzglêdu na nie równie¿ s± identyczne). Losowa inicjalizacja zapobiega temu zjawisku, co czêsto okre¶la siê mianem \textit{losowego ³amania symetrii}.

\subsubsection{Lokalne minima}

W zwi±zku z tym, ¿e metody gradientowe gwarantuj± jedynie zmniejszenie funkcji kosztu pomiêdzy iteracjami, metoda ta nie gwarantuje tego, ¿e ostateczne rozwi±zanie bêdzie globalnym minimum funkcji (o ile takie oczywi¶cie istnieje). Czêsto spotykanym zjawiskiem jest tzw. \textit{utkniêcie w lokalnym minimum}. Mo¿na to zaobserwowaæ np. przy wielokrotnym powtarzaniu treningu, gdy ostateczne wyniki sieci pochodz±cych z ró¿nych losowych inicjalizacji prowadz± do kompletnie ró¿nych wyników.

\subsubsection{Redukcja sta³ej uczenia w wypadku wysokiej i sta³ej warto¶ci funkcji kosztu (ang. \textit{learning rate reduction on plateau})} 

Kolejn± technik± wykorzystywan± podczas uczenia gradientowego jest tzw. \textit{redukcja sta³ej uczenia w wypadku sta³ej i wysokiej warto¶ci kosztu uczenia}. Opiszemy j± szerzej w zwi±zku z tym, ¿e zostanie wykorzystana w rozwi±zaniu opisanym w kolejnych rozdzia³ach tej pracy. Metoda ta, czêsto u¿ywana podczas uczenia gradientowego, zak³ada, ¿e gdy kolejne epoki nie przynosz± znacz±cej poprawy - oznacza to, ¿e lokalny kszta³t funkcji kosztu (w zale¿no¶ci od parametru) zawiera subtelno¶ci, które nie s± dostatecznie dobrze uwzglêdniane przez zbyt du¿± warto¶æ \textit{sta³ej uczenia}. Dlatego zwyk³o siê przemna¿aæ j± przez ustalon± sta³± $p < 1$ (czêsto przyjmuje siê $p=0.1$) w celu uwra¿liwienia metody optymalizacji na znacznie mniejsze, lokalne zmiany gradientu (por. \figurename{ \ref{r-o-p}}).

\begin{figure}\label{r-o-p}
\begin{center}
\includegraphics[scale=0.35]{r-o-p.png}
\caption{Przyk³ad zmiany funkcji koszty po redukcji sta³ej uczenia - za \cite{res-net}.}
\end{center}
\end{figure}

\subsubsection{Momentum}

W niektórych przypadkach uczenie napotyka na problem odwrotnej natury ni¿ ten opisany w poprzednim paragrafie - tzn. w momencie gdy warto¶æ funkcji kosztu jest du¿a, natomiast jej gradient niewielki i potrzeba d³ugiego czasu aby opu¶ciæ ten niekorzystny obszar (równie¿ okre¶lany mianem \textit{plateau}). Aby skutecznie przyspieszyæ czas trenowania czêsto stosowana jest tzw. metoda \textit{momentum}. Polega ona na tym, aby w algorytmie optymalizacji gradientowej zast±piæ dok³adn± warto¶ci gradientu - ¶redni± krocz±c± gradientów z poprzednich iteracji. Procedura \textit{momentum} wygl±da zatem nastêpuj±co:

\begin{enumerate}
\item Oblicz warto¶æ gradientu w i-tej operacji: $\delta_i = \frac{\partial J}{\partial w}$,
\item Zaktualizuj warto¶æ krocz±cej sumy gradientów: $update_i = \alpha *update_{i - 1} + (1 - \alpha)*\delta_i$.
\end{enumerate}

Jako pocz±tkow± warto¶æ $update_0$ przyjmuje siê zazwyczaj wektor zerowy.

\textit{Momentum} jest szczególnie u¿yteczne w przypadku stochastycznych metod gradientowych. Dziêki temu wyst±pienie znacz±cej perturbacji warto¶ci pochodnej jest równowa¿one przez jej u¶rednianie z warto¶ciami obliczonymi w poprzednich iteracjach, przez co wp³yw losowego zaburzenia jest znacz±co ograniczany.

\subsection{Stochastyczna optymalizacja gradientowa}

Bardzo czêsto, w przypadku gdy liczno¶æ zbioru danych $\mathcal{X}$ jest wyj±tkowo du¿a, obliczenie funkcji b³êdu, a tak¿e jej gradientów stanowi zadanie nieefektywne obliczeniowo. W takich przypadkach czêsto stosowan± technik± jest metoda stochastycznej optymalizacji gradientowej. Najczê¶ciej polega ona na losowym podziale zbioru na mniejsze czê¶ci i sukcesywnym stosowaniu metody gradientowej na kolejnych elementach tego podzia³u. Zwyczajowo zbiory dzieli siê porcje (ang. \textit{batch}) równej liczno¶ci i ze wzglêdu na rozmiar tych porcji wyró¿niamy:
\begin{itemize}
\item uczenie \textit{online} w którym ka¿da porcja sk³ada siê z jednego przyk³adu,
\item uczenie \textit{mini-batch}, w którym liczno¶æ porcji jest znacz±co mniejsza od rozmiaru ca³ego zbioru,
\item uczenie \textit{full-batch}, w którym mamy tylko jedn± porcjê - sk³adaj±c± siê z ca³ego zbioru.
\end{itemize}

Co warte podkre¶lenia, losowanie danych wprowadza do uczenia dosyæ spor± dozê losowo¶ci. Mo¿e to oczywi¶cie znacz±co spowolniæ proces uczenia lub doprowadziæ do tego, ¿e odnaleziony przez nas model bêdzie daleki od optymalnego. Okazuje siê jednak, ¿e w praktyce odpowiedni dobór rozmiaru próbki, w po³±czeniu z zastosowaniem metod granicznych \cite{minibatch} przynosi znacz±ce przyspieszenie algorytmów ucz±cych przy minimalnej stracie poprawno¶ci. Intuicja która za tym stoi, mówi, ¿e pomimo i¿ dana porcja mo¿e delikatnie zaburzyæ nasz model, to ¶rednia z kolejnych porcji aproksymuje gradient dostatecznie dobrze, istotnie poprawiaj±c warto¶ci parametry sieci \cite{loss-landscapes}.


\subsection{Metaoptymalizacja}

W poprzedniej podsekcji przedstawili¶my sposób znalezienia optymalnego rozwi±zania w przypadku gdy zale¿no¶æ funkcji b³êdu od parametrów jest ró¿niczkowalna. Jednak czêsto w tego typu zagadnieniach mamy do czynienia tak¿e z parametrami nie maj±cymi tej w³a¶ciowo¶ci. Tradycyjnie nazywamy takie parametry \textit{metaparametrami}. W tego typu przypadkach najczê¶ciej sposób dzia³ania wygl±da nastêpuj±co: 

\begin{enumerate}
\item Podzielmy zbiór paramterów $\Theta$ na $\Theta_g$ i $\Theta_m$ gdzie $\Theta_g$ to parametry ze wzglêdu na które funkcja b³êdu jest ró¿niczkowalna, a $\Theta_m$ to \textit{metaparametry}. Zak³adamy, ¿e $\Theta = \Theta_g \times \Theta_m$, a tak¿e, ¿e $\Theta_m = \Theta^1_m \times \dots \times \Theta^k_m$ dla pewnego $k$ naturalnego. 
\item Dla ka¿dego $i = 1,\dots,k$ wybierzmy skoñczony podzbiór $\bar{\Theta}^i_m$. Oznaczmy przed $grid = \bar{\Theta}^1_m \times \dots \times \bar{\Theta}^k_m$.
\item Dla ka¿dego $g \in grid$ ustalmy kryterium oceny danego zbioru metaparametrów. Mo¿e to byæ np. warto¶æ funkcji b³êdu uzyskana przy pomocy gradientowej optymalizacji parametrów z rodziny $\Theta_g$.
\item Dla ka¿dej warto¶ci $g \in grid$ obliczmy warto¶æ kryterium opisanego w podpunkcie 3 i jako ostateczny wybierzmy model który minimalizuje to kryterium.
\end{enumerate}

Powy¿szy schemat prezentuje tzw. algorytm \textit{grid search}. Jednak w przypadku gdy warto¶æ $|grid|$ jest du¿a - obliczenia te mog± byæ nieosi±galne ze wzglêdu na naturê obliczeniow±. W takich przypadkach stosuje siê lekko zmodyfikowany schemat nazywany \textit{random search}. W schemacie tym ustalamy pewn± liczbê $k <= |grid|$, a nastêpnie losujemy $k$ krotnie bez zwracania warto¶ci z $grid$ wybieraj±c na koñcu najlepsz± warto¶æ spo¶ród wylosowanych parametrów. O zaskakuj±cej skuteczno¶ci tego podej¶cia mo¿na poczytaæ chocia¿by w \cite{randomsearch}.

\section{Sztuczne Sieci neuronowe}

W tym rozdziale zajmiemy siê omówieniem podstawowego narzêdzia, z jakiego korzystaj± wszystkie algorytmy g³êbokiego uczenia, czyli sztucznych sieci neuronowych (ang. \textit{artificial neural network}). Co ciekawe, w literaturze nie istnieje jedna, formalna definicja wspólna dla wszystkich sieci neuronowych. Dlatego w poni¿szym rozdziale, przeanalizujemy ró¿ne przyk³ady sieci (przygl±daj±c siê ich historycznemu rozwojowi) które przybli¿± nam podstawowy koncept ich funkcjonowania, a tak¿e zg³êbimy biologiczn± inspiracjê, która stoi za ich wynaleziem, czyli uk³ad nerwowy zwierz±t z jego ewolucyjnym zwiêczeniem czyli ludzkim mózgiem.

\subsection{Biologiczna motywacja}

Badania naukowców i neurobiologów nad dzia³aniem ludzkiego mózgu trwaj± od ponad 100 lat i nadal skrywa on przed badaczami ogrom tajemnic. Jednak ju¿ dzisiaj mo¿emy z ca³± pewno¶ci± stwierdziæ, ¿e dzia³anie ludzkiego mózgu opiera siê na zorganizowanej wspó³pracy ogromnej ilo¶ci komórek nerwowych. Ka¿dy neuron przyjmuje od po³±czonych z nim innych neuronów nieregularnie w czasie aktywacje elektryczne i na ich podstawie sam emituje (lub nie) impulsy elektryczne do neuronów z którymi jest po³±czony. Zasada wspó³pracy ze sob± wielu jednostek obliczeniowych (jako tak± mo¿emy traktowaæ neuron) stanowi podstawê niemal ka¿dej architektury sieci neuronowych.

\subsection{Regresja logistyczna}

Jednym z najpopularniejszych algorytmów uczenia maszynowego jest aktualnie algorytm tzw. \textit{regresji logistycznej} \cite{logistic-regression}. Z naszej strony jest on interesujacy poniewa¿ mo¿emy interpretowaæ go jako pojedynczy obliczeniowy neuron. Zacznijmy jednak od formalnej definicji:

\begin{defi}
Modelem regresji logistycznej parametryzowanej wektorem $\left(\theta_0, \theta_1, \dots, \theta_n\right)$ bêdziemy nazywali funkcjê $f : \mathbb{R}^n \rightarrow (0,1)$ zadan± wzorem:

$$f_\theta(x) = \phi\left(\theta_0 + \sum_{i = 1}^{n}\theta_i x_i\right),$$

gdzie $\phi$ to sigmoidalna funkcja aktywacji opisana w paragrafie \ref{sigmoid}.

\end{defi}

Widzimy zatem, ¿e je¶li zinterpretujemy $x_1, x_2, \dots x_n$ warto¶ci impulsów z komórek nerwowych s±siaduj±cych z nasz±, parametry $\theta_1, \theta_2, \dots, \theta_n$ jako si³y po³±czeñ naszego neuronu ze swoimi s±siadami oraz $\theta_0$ jako wewnêtrzn± pobudliwo¶æ neuronów - to widzimy, ¿e w oparciu o interakcjê z s±siadami - nasz neuron oblicza sw± wewnêtrzn± aktywacjê, przekazywan± jako wynik funkcji $f$.
\subsubsection{Sigmoidalna funkcja aktywacji}\label{sigmoid}

\begin{defi}
Sigmoidaln± (logistyczn±) funkcj± aktywacji bêdziemy nazywaæ funkcjê :
$$S(x) = \frac{1}{1 + e^{-x}}.$$
\end{defi}

Oto niektóre z jej wa¿nych w³asno¶ci (por. \figurename{ \ref{sigmo}}):

\begin{uwaga}
Dla funkcji logistycznej zdefiniowanej powy¿ej zachodzi :
\begin{itemize}
\item $\lim_{x\rightarrow + \infty} S(x) = 1,$
\item $\lim_{x\rightarrow - \infty} S(x) = 0,$
\item $S'(x) = S(x)(1 - S(x)),$
\item $\lim_{x\rightarrow + \infty} S'(x) = 0$ \textit{saturacja prawostronna},
\item $\lim_{x\rightarrow - \infty} S'(x) = 0$ \textit{saturacja lewostronna}.
\end{itemize}
\end{uwaga}

\begin{figure}\label{sigmo}
\includegraphics[scale=0.7]{Sigmoid-wykres.png}
\caption{Wykres funkcji sigmoidalnej.}
\end{figure}

Zauwa¿my, ¿e na funkcjê sigmoidaln± mo¿emy spojrzeæ jako na ci±g³e przybli¿enie funkcji charakterystycznej zbioru $\{x\in\mathbb{R} : x > 0\}$. Kluczowe w zrozumieniu sekcji \ref{vanishing-gradien} bêdzie natomiast w³asno¶æ saturacji. Zauwa¿my, ¿e dla liczb o du¿ej warto¶ci bezwzglêdnej gradient funkcji logistycznej praktycznie siê zeruje. Mo¿e to spowodowaæ znacz±ce spowolnienie uczenia w wypadku wyboru metody optymalizacji gradientowej.

Wynik regresji logistycznej uznawany jest prawdopodobieñstwo przynale¿no¶ci do pewnej ustalonej klasy - zatem rozwi±zuje ona zagadnienie klasyfikacji binarnej. 

\subsubsection{Logistyczna funkcja kosztu - (ang. \textit{log-loss})}


Jedn± z podstaw sukcesu regresji logistycznej by³a nowa funkcja kosztu zadana wzorem:

$$J_{\mathcal{X}, \theta} = -\frac{1}{|\mathcal{X}|}\sum_{x\in\mathcal{X}}\log\left(f_\theta(x)\mathbb{I}_{y_x = 1} + \log(1 - f_\theta(x))\mathbb{I}_{y_x = 0}\right),$$

gdzie $y_x \ \left\{0, 1\right\}$ to prawid³owa klasa przyk³adu $x\in\mathcal{X}$, a $\mathbb{I}_{A}$ to funkcja charakterystyczna zbioru $A$.
Funkcja ta okaza³a siê dalece bardziej skuteczna od klasycznego b³êdu ¶redniokwadratowego oraz posiada teorioinformacyjn± interpretacjê jako tzw. odleg³o¶æ \textit{Kullbacka-Leiblera} pomiêdzy rozk³adem wyznaczonym przez $f_{\theta}$, a rozk³adem danych \cite{kullback-leibler}. Innym okre¶leniem logistycznej funkcji kosztu jest \textit{binarna entropia krzy¿owa} (ang. \textit{binary crossentropy}).

\subsubsection{Uogólnienie funkcji \textit{log-loss} do zagadnienia multiklasyfikacji}\label{categorical-cross-entropy}

Istnieje naturalne rozszerzenie regresji logistycznej do zagadnienia multiklasyfikacji zwane regresj± multinomialn±. W tym wypadku zamiast funkcjona³u u¿ywamy wielowymiarowego przekszta³cenia liniowego, miast funkcji sigmoidalnej u¿ywa siê tzw. funkcji \textit{softmax} $Softmax: \mathbb{R}^n\rightarrow\mathbb{R}^n$, zadanej wzorem:

$$Softmax(x_1, x_2, \dots, x_n)= \frac{\left(e^{x_1}, e^{x_2}, \dots, e^{x_n}\right)}{\sum_{j = 1}^{n}e^{x_j}},$$

Zauwa¿my, ¿e w naturalny sposób:

\begin{itemize}
\item  $Softmax(x_1, x_2, \dots, x_n)_i > 0$ dla ka¿dego $i \in \{1, \dots, n\}$,
\item $\sum_{i=1}^{n}Softmax(x_1, x_2, \dots, x_n)_i = 1$,
\item Je¶li $x_k > x_i$ dla $i\in\{1, \dots, n\}$ oraz $i \neq k$ to zachodzi $Softmax(x_1, x_2, \dots, x_n)_k > Softmax(x_1, x_2, \dots, x_n)_i$ dla $i\in\{1, \dots, n\}$ oraz $i \neq k$.
\end{itemize}

Pierwsze dwie w³asno¶ci pokazujê, ¿e funkcja $Softmax$ przekszta³ca wektor $(x_1, x_2, \dots, x_n$ w rozk³ad prawdopodobieñstwa. W³asno¶æ trzeci t³umaczy nazwê funkcji - indeks maksymalny wektora $(x_1, \dots, x_n)$ jest równie¿ indeksem maksymalnym $Softmax(x_1, \dots, x_n)$.

Oznaczmy teraz przez $M_\theta$ przekszta³cenie liniowe $\mathbb{R}^k\rightarrow\mathbb{R}^n$ zadane macierz± $\theta$. \textit{Regresj± multinomialn±} $F$ bêdziemy nazywaæ funkcjê $\mathbb{R}^k\rightarrow\mathbb{R}^n$ zadan± wzorem $F_\theta(x) = Softmax(M_\theta(x))$. Odpowiednikiem funkcji logistycznej funkcji kosztu jest nastêpuj±ca funkcja zwana \textit{kategoryczn± entropi± krzy¿ow±} (ang. \textit{categorical crossentropy}:

$$J_{\mathcal{X}, \theta} = -\frac{1}{|\mathcal{X}|}\sum_{x\in\mathcal{X}}\sum_{i=1}^{k}\log Soft_\theta(x)_i\mathbb{I}_{y_x = i}.$$

Wariacj± tej funkcji kosztu jest tzw. \textit{wa¿ona entropia krzy¿owa} (ang. \textit{weighted categorical crossentropy}:

$$J_{\mathcal{X}, \theta} = -\frac{1}{|\mathcal{X}|}\sum_{x\in\mathcal{X}}\sum_{i=1}^{k}w_i\log Soft_\theta(x)_i\mathbb{I}_{y_x = i},$$

gdzie $w \in \mathbb{R}_+^k$ to tzw. wektor wag. Intuicyjnie - im wiêksza waga danej klasy - tym bardziej proces uczenia skupia siê na prawid³owym jej klasyfikowaniu. 

\subsubsection{Uogólnienie powy¿szych funkcji kosztu do dowolnego modelu}

Zarówno dla \textit{logistycznej funkcji kosztu} oraz \textit{kategorycznej entropii krzy¿owej} nie jest wymagane aby wyniki u¿ywane do jej obliczenia pochodzi³y z przekszta³ceñ liniowych. Regresjê logistyczn± mo¿emy zast±piæ dowoln± funkcj± $model_b: \mathbb{R}^n\rightarrow\mathbb{R}$ z³o¿on± z funkcj± sigmoidaln± $S$, natomiast regresjê mutlinomialn± mo¿emy zast±piæ dowoln± funkcj± $model_c: \mathbb{R}^n\rightarrow\mathbb{R}^k$ z³o¿on± z funkcj± $Soft$ i nadal uzyskaæ u¿yteczn± funkcjê kosztu. W dalszej czê¶ci funkcje $model_b$ i $model_c$ bêd± pewnymi sieciami neuronowymi.

\section{Klasyczne sieci neuronowe oraz algorytm wstecznej propagacji}

Regresja logistyczna - dziêki swojej prostocie - zyska³a sobie miano bardzo popularnej metody w dziedzienia uczenia maszynowego. Ogromnym problemem jaki napotykamy jednak przy jej u¿ywaniu jest to, ¿e dziêki swojej prostocie - nie jest w stanie efektywnie nauczyæ siê bardziej skomplikowanych funkcji. Szybko jednak zauwa¿ono, ¿e tak jak uk³ady nerwowe zwierz±t nie sk³adaj± sie tylko i wy³±cznie z jednego neuronu, tylko z ich wspó³dzia³aj±cego ze sob± konglomeratu, tak skutecznie dzia³aj±cych modeli nie nale¿y szukaæ w funkcjach na¶laduj±cych pojedyncze neurony, lecz w z³o¿eniu takich funkcji ze sob±. Tak narodzi³a siê idea \textit{sieci wielowarstwowych} które stanowi± podstawê tak¿e algorytmów \textit{deep-learning}.

\subsection{Topologie sieci}

Aby pozbyæ siê problemu jaki niesie ze sob± prostota perceptronu, przyjêto, ¿e wyniki z wielu perceptronów, które jako argumenty przyjmuj± ten sam wektor $x$ czyli:

$$y^{(1)}_k = \phi_1\left(\sum_{i = 1}^{n} x_i w^{(1)}_{i, k} + w^{(1)}_{0, k}\right),$$

stanie siê automatycznie \textit{wej¶ciem} dla kolejnych perceptronów :

$$y^{(2)}_j = \phi_2\left(\sum_{k = 1}^{m} y_k w^{(2)}_{k, j} + w^{(2)}_{0, j}\right).$$

Oczywi¶cie proces tworzenia takiej sieci mo¿na iterowaæ i tak np. trzecia wartstwa mia³aby postaæ :

$$y^{(3)}_l = \phi_3\left(\sum_{j = 1}^{o} y_j w^{(3)}_{j, l} + w^{(3)}_{0, l}\right).$$

\begin{figure}\label{siec}
\centering 
\includegraphics[scale=0.7]{SiecXor.png}
\caption{Przyk³ad architektury wartstwowej sieci typu \textit{feed-forward}. Sieæ o tej architekturze jest w stanie nauczyæ siê logicznej funkcji XOR.}
\end{figure}

Dla uproszczenia przyjêli¶my, ¿e w obrêbie warstwy funkcje aktywacji s± takie same, jednak nie stanowi to koniecznego wymogu. Przedstawiona powy¿ej architektura stanowi przyk³ad architektury warstwowej - kolejne warstwy przyjmuj± jako swoje argumenty rezultaty obliczeñ z poprzednich warstw (st±d nazwa \textit{wielowarstwowy perceptron}). O wektorze wej¶ciowym $x$ zwyk³o siê zazwyczaj mówiæ jako o warstwie wej¶ciowej (ang.\textit{input layer}), natomiast o ostatniej wartstwie jako warstwie wyj¶ciowej (ang. \textit{output layer}). Oczywi¶cie istniej± tak¿e architektury w których dopuszczamy po³±czenia pomiêdzy warstwami innymi ni¿ kolejne (ang. \textit{skip-connections} \cite{skip-connections}). Topologiê ka¿dej sieci zwykle przedstawia siê w postaci skierowanego grafu z³o¿eñ (patrz rysunek \ref{siec}). Je¶li w grafie tym nie ma cykli, sieæ tak± nazywamy sieci± \textit{w przód} (ang. \textit{feed-forward neural net}), w przeciwnym przypadku mamy do czynienia z sieci± rekurencyjn± (ang. \textit{recurrent neural network}).

\begin{figure}
\centering 
\includegraphics[scale=0.7]{Recurrent.png}
\caption{Przyk³ad architektury rekurencyjnej. Zwróæmy uwagê na skierowany cykl w grafie po³±czeñ.}
\end{figure}

\subsection{Wielowarstwowa sieæ neuronowa jako uniwersalny aproksymator}

Opisane powy¿ej architektury nie s± oczywi¶cie jedyn± form± z³o¿enia ze sob± wielu perceptronów. £±cz± one jednak ze sob± dwie podstawowe wa¿ne cechy - prostotê parametryzacji zbiorem wag $w_{i}^{(l)}$ wraz z ogromn± zdolno¶ci± aproksymacji. O klasie funkcji aproskymowalnych przez sieci neuronowe mówi poni¿sze twierdzenie (dowód mo¿na znale¼æ np. tu \cite{cybenko}).

\begin{twierdzenie}
Niech $f : \mathbb{R}^{n} \rightarrow \mathbb{R}$ bêdzie dowoln± funkcj± ci±g³± o zwartym no¶niku. Dla ka¿dego $\epsilon > 0$ istnieje wówczas dwuwarstwowa sieæ neuronowa $f^* :  \mathbb{R}^{n} \rightarrow \mathbb{R}$ z sigmoidaln± funkcj± aktywacji dla której :
$$\sup_{x\in \mathrm{supp}f} \left|f(x) - f^*(x)\right|\leq \epsilon.$$
\end{twierdzenie}

Powy¿sze twierdzenie mówi nam o problemie regresji funkcji g³adkich. Analogiczne twierdzenie \cite{hornik} mówi nam, ¿e dowolny problem klasyfikacji da siê rozwi±zaæ z dowoln± dok³adno¶ci± przy pomocy trójwarstwowej sieci neuronowej. 

W³asno¶æ uniwersalnej aproksymacji daje nam gwarancjê, ¿e dla ka¿dego problemu, znajdziemy sieæ neuronow± która rozwi±zuje go z dowoln± dok³adno¶ci±. Nie nale¿y jednak przeceniaæ jej znaczenia - ich dowody nie przedstawiaj± nam ¿adnej skutecznej metody do znajdowania architektury oraz odpowiednich parametrów sieci.

\subsection{Algorytm wstecznej propagacji}

To, ¿e do³o¿enie kolejnych warstw zwiêksza mo¿liwo¶ci perceptronu wiedziano ju¿ w latach '60 XXw. To co przyczyni³o siê do prze³amania z³ego trendu, który nasta³ po rozczarowaniu zwi±zanym z ograniczeniami perceptronu by³ kolejny skuteczny algorytm uczenia. W tym przypadku kluczem sta³ siê algorytm wstecznej propagacji, dzia³aj±cy dla architektur typu \textit{feed-forward}. I ponownie - to co uderza, to ju¿ nie prostota samego algorytmu, lecz prostota koncepcji, która sta³a za jego wynalezieniem. To co okaza³o siê kluczowym w tym przypadku to idea znana z rachunku ró¿niczkowego - czyli regu³a ³añcuchowa.

W swej najprostszej postaci algorytm ten jest kolejnym praktycznym zastosowaniem metody optymalizacji gradientowej. W sensie obliczeniowym, algorytm wykorzystuje brak cyklów w sieci neuronowej, co znacz±co u³atwia obliczenia pochodnej b³êdu ze wzglêdu na ka¿dy parametr $w_{i}^{(j)}$. Spróbujmy prze¶ledziæ jak wygl±da obliczanie tych pochodnych, w przypadku gdy za funkcjê b³êdu przyjmiemy b³±d ¶redniokwadratowy, a za funkcjê aktywacji funkcjê sigmoidaln± dla sieci z jednym neuronem w wartstwie wyj¶ciowej. Przy zadanym zbiorze $\mathcal{X}$ warto¶æ pochodnej funkcji b³êdu ze wzglêdu na wyniki warstwy wyj¶ciowej $y_{x}^{(out)} = f^{*}(x)$, gdy dla ustalonego $x \in \mathcal{X}$ prawid³owa warto¶æ wynosi $y_x$ jest zadana wzorem :


\begin{figure}
\centering 
\includegraphics[scale=0.7]{Backprop.png}
\caption{Rysunek pomocniczy dla procesu wstecznej propagacji.}
\end{figure}

$$\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial y^{(out)}} = \frac{\partial
\left(\frac{1}{2|\mathcal{X}|}\sum_{x \in \mathcal{X}} \left(y_{x}^{(out)} - y_{x}\right)^2\right)}{\partial y^{(out)}} = \sum_{x \in \mathcal{X}}\left(y_{x}^{(out)} - y_{x}\right).$$

Za³ó¿my teraz, ¿e dla ustalonej warstwy (dla ustalenia uwagi oznaczmy, ¿e jest to $k$-ta warstwa sieci) znamy pochodn± ze wzglêdu na ka¿de wyj¶cie $y_{i}^{(k)}$ czyli :

$$\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial y_{i}^{(k)}}.$$

Przyjmuj±c wtedy za $x_i^{(k - 1)} = \sum_{j = 1}^{n_{k - 1}} w_{i, j}^{(k - 1)} y_{j}^{(k - 1)}$ Mamy wówczas (korzystaj±c z regu³y ³añcuchowej) :

$$\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial w_{i,j}^{(k - 1)}} = 
\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial y_{i}^{(k)}}
\frac{\partial y_{i}^{(k)}}{\partial x_{i}^{(k - 1)}}\frac{\partial x_i^{(k - 1)}}{\partial w_{i,j}^{(k - 1)}}.$$

Powy¿szy wzór, korzystaj±c z w³asno¶ci funkcji sigmoidalnej upraszcza siê do :

$$\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial w_{i, j}^{(k - 1)}} = 
\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial y_{i}^{(k)}}\left(1 - \phi(x_{i}^{(k - 1))}\right)\phi(x_{i}^{(k - 1)})y_{j}^{(k - 1)}.$$

Regu³a ³añcuchowa ponadto pozwala nam obliczyæ warto¶æ: 

\begin{equation}
\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial y_{j}^{(k - 1)}} = 
\sum_{i = 1}^{n_{k - 1}}\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial y_{j}^{(k)}}
\frac{\partial y_{j}^{(k)}}{\partial y_{i}^{(k - 1)}} =
\sum_{i = 1}^{n_{k - 1}}\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial y_{j}^{(k)}}
\frac{\partial y_{j}^{(k)}}{\partial x_{i}^{(k - 1)}}
\frac{\partial x_{i}^{(k - 1)}}{\partial y_{j}^{(k - 1)}}.
\end{equation}

Po uproszczeniu (korzystaj±c z w³asno¶ci funkcji sigmoidalnej) otrzymujemy :

$$
\frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial y_{j}^{(k - 1)}} = \frac{\partial J_{\mathcal{X}}\left(\Theta\right)}{\partial y_{i}^{(k)}}\sum_{i = 1}^{n_{k - 1}}
\left(1 - \phi(x_{i}^{(k - 1)})\right)\phi(x_{i}^{(k - 1)})w_{i, j}^{(k - 1)}.$$

Warto¶ci te mo¿emy nastêpnie wykorzystaæ do obliczenia pochodnych ze wzglêdu na wagi z ni¿szych warstw. Zatem na mocy zasady indukcji matematycznej mo¿emy policzyæ gradient funkcji kosztu ze wzglêdu na dowolny parametr.

Zauwa¿my, ¿e w powy¿sze rozumowanie z ³atwo¶ci± mo¿na rozszerzyæ na przypadek sieci w których istniej± po³±czenia miêdzy warstwami (tj. gdy wyj¶cie z warstwy $k$ jest wej¶ciem nietylko do warstwy $k + 1$, ale równie¿ dla warstwy $l > k + 1$). Wzory te - w ogólnej postaci, mo¿na równie¿ rozszerzyæ na inne przypadki funkcji b³êdu oraz aktywacji. 

Warto równie¿ podkre¶liæ, ¿e technika ta stosowana jest tak¿e w przypadku rekurencyjnych sieci neuronowych, przez odpowiednie przedstawienie sieci rekurencyjnej, jako sieci typu \textit{feed-forward} z dodatkowym kryterium, aby czê¶æ wag w sieci mia³y tak± sam± warto¶æ.

\subsubsection{Zjawisko znikaj±cego gradientu (ang. \textit{vanishing gradient problem})}\label{vanishing-gradien}

Jak mogli¶my zauwa¿yæ - obliczenia pochodnych w danej warstwie zale¿± bezpo¶rednio od warto¶ci pochodnych w warstwach poprzednich. W wypadku sieci o g³êboko¶ci wiêkszych ni¿ $5$ \cite{choromanska} mo¿e to prowadziæ do tzw. zjawiska zanikaj±cego gradientu, gdzie norma gradientu ze wzglêdu na g³êbsze warstwy staje siê na tyle ma³a, spada poni¿ej dok³adno¶ci zmiennoprzecinkowej algorytmów ucz±cych (w wypadku sieci neuronowych jest to najczê¶ciej format \texttt{float 32} którego dok³adno¶æ wynosi ok. $10^{-6}$), ¿e uczenie \textit{de facto} zatrzymuje siê.

Istnieje wiele technik maj±cych na celu unikniêcie tego zjawiska. Min. opisane w rozdziale 4 techniki klasyfikatorów pomocniczych \ref{auxiliary-classifiers} oraz po³±czenia residualne \ref{residual-connections}.

\subsubsection{Zjawisko przesuniêcia warto¶ci (ang. \textit{covariate shift}) i technika normalizacji porcjowej (ang. \textit{Batch Normalization})}

Dosyæ powa¿n± wad± techniki wstecznej propagacji jest wystêpowanie tzw. zjawiska przesuniêcia warto¶ci w sieciach typu \textit{feed-forward}. Intuicyjnie polega ono na tym, ¿e pod±¿anie w kierunku najmniejszego spadku w dwóch kolejnych warstwach mo¿e doprowadziæ do tego, ¿e pó¼niejsza z nich bêdzie oczekiwa³a kompletnie innych warto¶ci ni¿ te które dostarcza jej warstwa poprzednia. Czêsto znacznie pogarsza to stabilno¶æ oraz efektywno¶æ procesu uczenia.

Aby unikn±æ tego zjawisko czêsto stosuje siê tzw. \textit{technikê normalizacji porcjowej} (ang. \textit{Batch Normalization} \cite{batch-normalization})  gdzie ka¿da kolejna porcja danych u¿ywana w procesie uczenia - jest u¶redniana przez swoj± ¶redni± porcjow± $y^k_p$:

$$\bar{y}^{(k)} = y^{(k)} - y^{(k)}_{p},$$

standaryzowana przez porcjowe odchylenie standardowe $\sigma^k_p$:

$$\bar{\bar{y}}^{(k)} = \frac{\bar{y}^{(k)}}{\sigma^k_p},$$ 

a nastêpnie przesuwana o wyuczalny wektor $m^{(k)}_p$  i skalowana przez wyuczalny czynnik $c^{(k)}_p$:

$$y^{(k)}_b = \bar{\bar{y}}^{(k)} * c^{(k)}_p + m^{(k)}_p.$$ 

Odbywa siê nie tylko na poziomie normalizacji danych wej¶ciowych, ale tak¿e pomiêdzy ka¿dymi kolejnymi warstwami. Ka¿de wej¶cie do kolejnej warstwy ma tak± sam± ¶redni± $m^{(k)}_p$ oraz odchylenie standardowe $c^{(k)}_p$ dziêki czemu zjawisko \textit{covariate shift} zostaje znacz±co ograniczone. W dniu dzisiejszym \textit{normalizacja porcjowa} uznawana jest za obowi±zkow± technikê normalizacji wiêkszo¶ci architektur sieci neuronowych. 


\subsection{Interpretacja probabilistyczna sieci neuronowych}

Dosyæ interesuj±cym spojrzeniem na zagadnienie poszukiwania optymalnych warto¶ci parametrów sieci neuronowej, jest przedstawienie tego zagadnienia optymalizacyjnego jako maksymalizowanie funkcji wiarygodno¶ci (dok³adnie jej logarytmu) modeli sposród ustalonej rodziny. Metodê tê, znan± ze statystyki jako estymacja metod± najwiêkszej wiarygodno¶ci (\textit{ang.} maximum likelihood estimation (MLE)). Rozwa¿my to poni¿szym przyk³adzie.

\begin{przyklad}
Rozwa¿my przez $f_{\theta}$ parametryzowan± wagami $\theta \in \Theta$ sieæ neuronow± o ustalonej architekturze typu feed forward. Rozwa¿my wówczas rodzinê rozk³adów warunkowych zadanych wzorem :
 
$$ \mathbb{P}\left(y | \theta, x\right) \sim \mathcal{N}\left(f_{\theta}(x), \sigma\right),$$

dla pewnej ustalonej liczby $\sigma > 0$. Mo¿emy to zinterpretowaæ w ten sposób, ¿e przy ustalonym $x$, rozk³ad $y$ przedstawia siê jako :

$$ y = f_{\theta}(x) + \mathbf{X},$$

gdzie $\mathbf{X} \sim \mathcal{N}\left(0, \sigma\right).$ Za³ó¿my teraz, ¿e nasz zbiór treningowy $\mathcal{X}$ wyznacza zbiór do zadania regresji i mo¿emy go przedtawiæ w postaci :
$$\mathcal{X} = \left\{\left(x_1, y_1\right), \left(x_2, y_2\right), \dots, \left(x_n, y_n\right)\right\} \subset \mathbb{R}^{n} \times \mathbb{R}.$$

Zauwa¿my, ¿e je¶li przyjmiemy, ¿e elementy naszego zbioru treningowego s± niezale¿ne oraz zgodne z powy¿szym rozk³adem prawdopodobieñstwa, to wówczas funkcja wiarygodno¶ci ustalonego zestawu wag $\theta \in \Theta$ wyra¿a siê wzorem:

$$\mathcal{L}\left(\theta, \mathcal{X}\right) = \prod_{i = 1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{\left(y - f_{\theta}(x)\right)^{2}}{2\sigma}},$$

a zatem logarytm funkcji wiarygodno¶ci wyra¿a siê wzorem :

$$\log \mathcal{L}\left(\theta, \mathcal{X}\right) = -\frac{1}{2\sigma}\sum_{i = 1}^{n}\left(y - f_{\theta}(x)\right)^2 + C,$$

gdzie $C = -\frac{n}{2} \log 2\pi\sigma^{2}.$ Widzimy zatem, ¿e zadanie maksymalizacji logarytmu funkcji wiarygodno¶ci jest równowa¿ne rozwi±zaniu zadania minimalizacji ¶redniokwadratowej funkcji b³êdu dla rodziny funkcji neuronowych $f_\theta$, albowiem :

$$\arg \max_{\theta \in \Theta} -\frac{1}{2\sigma}\sum_{i = 1}^{n}\left(y - f_{\theta}(x)\right)^2 + C = \arg \min_{\theta \in \Theta}\frac{1}{2\sigma}\sum_{i = 1}^{n}\left(y - f_{\theta}(x)\right)^2.$$

Analogia ta pozwala czêsto skorzystaæ z wygody dualnego patrzenia na zadanie uczenia - jako z jednej strony zagadnienia stricte optymalizacyjnego, a z drugiej - pokrewnego metod± statystycznym. Pozwala to skorzystaæ z wygodnych intuicji probabilistycznych, a tak¿e np. na ³atwe korzystanie z metod Bayesowskich w zagadnieniach machine learningu.

\end{przyklad}

Oczywi¶cie funkcja ¶redniokwadratowa nie jest jedyn± funkcj± b³êdu, dla której powy¿sza analogia ma miejsce. Je¶li np. zarz±damy aby :

$$ \mathbb{P}\left(y | \theta, x\right) \sim \mathbb{L}\left(f_{\theta}(x), 1\right),$$

gdzie $\mathbb{L}\left(f_{\theta}(x),\ 1\right)$ to rozk³ad Laplace'a z parametrami $f_{\theta}(x)$ oraz $1$, równowa¿n± metodzie MLE metod± optymalizacji bêdzie minimalizacja z nastêpuj±c± funkcj± b³êdu :

$$J_\mathcal{X}\left(\theta\right) = \sum_{x\in \mathcal{X}} \lVert f_{\theta}(x) - y\rVert_{1}.$$

Widzimy, ¿e rozumowanie to mo¿na uogólniæ niemal dla ka¿dej funkcji b³êdu, dla której istnieje taki rozk³ad prawdopodobieñstwa $p\left(\theta, x\right)$, ¿e 

$$ J_\mathcal{X}\left(\theta\right) = -C\sum_{x \in \mathcal{X}} \log p\left(x, \theta\right) + D,$$

gdzie $C, D \in \mathbb{R}$ to pewne sta³e. Przyk³ad zastosowania intuicji probabilistycznej mo¿emy zobaczyæ ju¿ w poni¿szym rozdziale.

\subsection{Regularyzacja sieci neuronowych}

W tej podsekcji chcia³bym opisaæ niektóre prostsze metody regularyzacji stosowane w sieciach neuronowych. Przez regularyzacjê rozumiemy dzia³ania maj±ce na celu zmniejszenie skutku procesu przeuczenia. W kolejnych rozdzia³ach poznamy inne metody regularyzacji (w tym te, które s± esencjonalne dla algorytmów \textit{deep learning}), w tym rozdziale jednak przedstawimy elementarne metody radzenia sobie ze zjawiskiem \textit{overfittingu}.

\subsubsection{Kara zwi±zana z $\lVert\Theta\rVert_{2}$}

Podstawow± metod± regularyzacji jest zmiana funkcji b³êdu poprzed dodanie dodatkowego sk³adnika, który zwiêksza warto¶æ b³êdu gdy norma Euklidesowa wektora wag jest du¿a. Prowadzi to do nowej funkcji b³êdu zadanej zazwyczaj wzorem:

$$J^{R}_\mathcal{X}(\Theta) = J_\mathcal{X}(\Theta) + \frac{\lambda}{2}\sum_{\theta \in \Theta}\theta^2$$

lub stosuj±c zapis wektorowy : 

$$J^{R}_\mathcal{X}(\Theta) = J_\mathcal{X}(\Theta) + \frac{\lambda}{2}\Theta\Theta^{T}.$$

dla pewnego $\lambda \in \mathbb{R}$. Warto zauwa¿yæ, ¿e stosuj±c probabilistyczn± interpretacjê sieci neuronowych, minimalizacja powy¿szej funkcji b³êdu jest równowa¿na maksymalizacji funkcji ufno¶ci przy za³o¿eniu rozk³adu \textit{a priori} na zbiorze parametrów $\Theta$:

$$\theta_{i} \sim \mathcal{N}\left(0 , \frac{1}{\lambda}\right), iid.$$

Za³ó¿my bowiem, ¿e istnieje rozk³ad $p \left(\theta, x\right)$ dla którego :

$$ J_\mathcal{X}\left(\theta\right) = -C\sum_{x \in \mathcal{X}} \log p\left(x, \theta\right) + D,$$

ale wówczas uwzglêdniaj±c bayesowskie za³o¿enie o warto¶ci parametrów $\theta$ otrzymujemy :

$$ J^{R}_\mathcal{X}\left(\theta\right) = -C\sum_{x \in \mathcal{X}} \log \left(\frac{p\left(x, \theta\right)}{p\left(\theta\right)} \right) + D = -C\sum_{x \in \mathcal{X}} \log \left(p\left(x, \theta\right)\right) + \frac{\lambda}{2}\sum_{\theta \in \Theta}\theta^2 + D',$$

co jest równowa¿ne powy¿szej formie funkcji kosztu.

\subsubsection{Kara zwi±zana z $\lVert\Theta\rVert_{1}$}

Inn± czêsto stosowan± metod± regularyzacji jest tzw. metoda \textit{lasso}, polegaj±ca na dodaniu do funkcji b³êdu dodatkowego sk³adnika zwiêkszaj±cego funkcjê b³êdu gdy tym razem pierwsza norma wektora wag jest du¿a. Funkcjê tê mo¿emy zapisaæ w postaci :

$$J^{R}_\mathcal{X}(\Theta) = J_\mathcal{X}(\Theta) + \sum_{\theta \in \Theta}|\theta| = 
J_\mathcal{X}(\Theta) + \lambda\lVert\Theta\rVert_{1}.$$

Analogicznie jak w poprzednim przypadku, mo¿emy potraktowaæ dodatkowy sk³adnik jako do³o¿enie Bayesowskiego za³o¿enia o rozk³adzie parametru wedle wzoru :

$$\theta \sim \mathbb{L}\left(0, \frac{1}{\lambda}\right),$$

gdzie przez $\mathbb{L}(a,b)$ oznaczamy rozk³ad Laplace'a z parametrami $a,b$.

\subsection{Czym ró¿ni± siê powy¿sze kary?}

Warto wspomnieæ o dosyæ powa¿nych koncepcyjnych ró¿nicach pomiêdzy powy¿szymi wagami. Przyjmuje siê \cite{lasso}, ¿e o ile kara $\lVert\Theta\rVert_{2}$ stara siê niedopuszczaæ aby warto¶ci $\theta_i$ by³y wyra¼nie wiêksze od $0$ (funkcja kwadratowa ro¶nie szybko dla liczb $\gg\ 1$, o tyle kara $\lVert\Theta\rVert_{1}$ sprawia, ¿e znacznie czê¶ciej du¿a czê¶æ parametrów zbiór parametrów $\theta_i$ jest zaniedbywalnie wiêksza od $0$. Dlatego te¿ tê drug± metodê zwyk³o nazywaæ siê metod± \textit{lasso} i czêsto stosuje siê j± do eliminacji zbêdnych parametrów, poprzez odrzucenie tych, dla których w wyniku uczenia warto¶ci otrzymane spe³nia³y $\theta \approx 0$.

\subsection{Intuicje dotycz±ce warstw sieci neuronowych}

To, ¿e trójwarstwowa sieæ neuronowa mo¿e poradziæ sobie z praktycznie ka¿dym zadaniem \textit{machine learningowym} jest faktem, udowodnionym teoretycznie, jednakowo¿ dowód ten jest niepraktyczny w tym sensie, ¿e dla zadanego zadania pokazuje istnienie rozwi±zania, bez dok³adnego przepisu na jego uzyskanie. Poni¿ej chcia³bym pokazaæ intuicyjny szkic dowodu tego, ¿e dowolny zbiór otwarty w $\mathbb{R}^n$ mo¿na przybli¿yæ przy pomocy sieci z dwiema warstwami ukrytymi :

\begin{enumerate}
\item Jednostki z sigmoidaln± funkcj± aktywacji, których argumentami s± neurony z warstwy wej¶ciowej, s± w stanie reprezentowaæ przybli¿one funkcje charakterystyczne pó³przestrzeni kowymiaru 1 (je¶li argumenty $x \in \mathbb{R}^n$,
\item Pojedynczy perceptron, z sigmoidaln± funkcj± aktywacji, jest w stanie w przybli¿ony sposób na¶ladowaæ operacje logiczne typu $\textsc{and}$ oraz $\textsc{or}$ je¶li swoje argumenty potraktuje jako przybli¿one warto¶ci \textit{boolowskie}.
\item W zwi±zku z powy¿szym, sieæ neuronowa z jedn± warstw± ukryt± i sigmoidaln± funkcj± aktywacji jest w stanie nauczyæ siê funkcji charakterystycznej dowolnego zbioru bêd±cego przeciêciem pó³przestrzeni (w szczególno¶ci - kostki $k-$wymiarowej, gdzie $k \leq n$).
\item Sieci neuronowe z dwiema warstwami ukrytymi potrafi± nauczyæ siê zatem przybli¿onej funkcji charakterystycznej dowolnej funkcji bêd±c± sum±, przeciêciem zbiorów których funkcje charakterystyczne mog± zostaæ uzyskane przy pomocy sieci z podpunktu 3. W szczególno¶ci - z dowolnym przybli¿eniem - dowolny zbiór otwarty $\mathcal{U} \subset \mathbb{R}^{n}.$ 
\end{enumerate}

Powy¿szy dowód uznajê za warto¶ciowy z dwóch powodów :

\begin{enumerate}
\item Pokazuje jak wielowarstwowa sieæ neuronowa koduje hierarchiczny zbiór cech, który nastêpnie wykorzystuje do budowania ostatecznego rozwi±zania.
\item W zwi±zku ze sw± ide± pokazuje, ¿e niekonstruktywne dowody w³asno¶ci uniwersalnej aproksymacji opieraj± siê li tylko na budowaniu lokalnych przybli¿eñ ostatecznego rozwi±znia, co koniec koñców mo¿e doprowadziæ do tzw. \textit{przekleñstwa wymiarowo¶ci} (ang. \textit{curse of dimensionality} \cite{curse-of-dimensionality}). 
\end{enumerate}

Oba powy¿sze wnioski rozwiniemy w kolejnych rozdzia³ach.

\subsection{Reprezentacja rozproszona}

Idea dzia³ania sieci opiera siê na uczeniu opisanej w poprzedniej podsekcji - struktury \textit{cech} potrzebnych do rozwi±zania zadanego problemu. Z jednej strony - stanowi to klucz do zrozumienia ogromnego sukcesu sieci neuronowych w ostatnim czasie. Fakt, ¿e jeden spójny algorytm uczenia mo¿e wyrêczyæ badacza z wyszukiwania cech niezbêdnych do rozwi±zania danego problemu (np. przy wspomnianym we wstêpie zagadnieniu rozpoznawania obrazu ekstrakcja takich cech by³a przez wiele lat ciê¿k± i dobrze p³atn± prac±), przerzucaj±c ciê¿ar pracy na zaprojektowanie odpowiedniej architektury sieci, funkcji kosztu dla procesu optymalizacji, a potem na moc obliczeniow± wspó³czesnych komputerów. Widzimy zatem, ¿e automatycznie budowany zbiór cech stanowi klucz do zrozumienia dzia³ania wielowarstwowych sieci neuronowych.

W klasycznych warstwowych sieciach neuronowych typu \textit{feed-forward} zbiór tych cech stanowi hierarchiczny konglomerat cech, w którym cechy reprezentowane w danej warstwie tworzone s± przez transfomacj cech reprezentowanych w warstwie poprzedniej \ref{cnn-feat}, \cite{zeiler-fergus}. Jeden z przyk³adów takiej hierarchiczo¶ci przedstawi³em w szkicu dowodu aproksymacyjnego z poprzedniej podsekcji.  

Koncepcyjnie - zrezygnowanie z warstwowo¶ci, przy zachowaniu typu \textit{feed-forward} pozwala budowaæ nowe cechy przy pomocy konceptów wyuczonych przez ni¿sze warstwy (por. \figurename{ \ref{cnn-feat}}). Dalsza relaksacja za³o¿eñ, czyli dopuszczenie cyklów w architekturze pozwala na budowanie cech oraz definicyjnych powi±zañ miêdzy nimi. W praktyce jednak, obliczeniowe w³asno¶ci architektury \textit{feed-forward} sprawiaj±, ¿e to w³a¶nie te sieci stanowi± wspó³cze¶nie awangardê w¶ród najskuteczniejszych rozwi±zañ zadañ \textit{machine learningu}. Nawet sieci rekurencyjne prezentuje siê z tej przyczyny, w tej formie, dodaj±c odpowiednie ograniczenia i warunki na warto¶ci odpowiednich wag \cite{unfolding-rnn}.

\begin{figure}\label{cnn-feat}
\centering 
\includegraphics[scale=0.48]{zeilercnnfeatures.jpeg}
\caption{Wizualizacja cech wyuczonych przez tzw. konwolucyjn± sieæ neuronow±  z \cite{zeiler-fergus}.}
\end{figure}


\subsubsection{G³êboka hierarchiczna struktura przyczyn± sukcesu algorytmów z rodziny Deep Learning}

Przyjmuje siê, ¿e podstawow± przyczyn± ogromnego sukcesu g³êbokich sieci jest efektywna umiejêtno¶æ uchwycania hierarchicznych struktur wiedzy, która stanowi podstawê kompleksowo¶ci wielu z najwa¿niejszych wspó³cze¶nie problemów \textit{machine learning'owych} \cite{bengio}. Prawid³owe zrozumienie rz±dz±cych tym prawide³ to nadal wielkie wyzwanie dla badaczy zajmuj±cych siê sztuczn± inteligencj±. Mo¿emy jednak na kilku przyk³adach przyjrzeæ siê dlaczego uchwycenie takiej struktury mo¿e okazaæ siê zbawienne dla efektywnego nauczenia modelu dla wielu wa¿nych zagadnieñ wspó³czesnego \textit{AI} \cite{hierarchical}:

\begin{itemize}
\item Wiedza opisuj±ca np. rozpoznawanie twarzy ma hierarchiczn± strukturê. Podstawowe pojêcia takie jak kreski, ³uki, zabarwienia - s³u¿± do budowania bardziej z³o¿onych pojêæ takich jak oczy, policzki - które z kolei tworz± rozmaite rysy, twarze charakterystyczne dla rasy, p³ci, etc. 
\item Wiedza opisuj±ca rozpoznawanie mowy równie¿ ma podobn± strukturê - Podstawowe pojêcia tj. g³oski bior± udzia³ w tworzeniu fonemów, które sk³adaj± siê na s³owa tworz±ce zdania etc.
\end{itemize}

Przyjmuje siê, ¿e w³a¶nie taka postaæ wiedzy - naturalnie uchwycana przez model o hierarchicznej strukturze - stanowi podstawê sukcesów \textit{g³êbokich sieci}. W codziennej praktyce czêsto potwierdza siê - ¿e modele takie nie dzia³aj± tak efektywnie dla problemów o prostszej strukturze - chocia¿by ze wzglêdu na z³o¿ono¶æ przestrzeni parametrów, a tak¿e - z³o¿ono¶æ obliczeniow± procesu uczenia. 

\chapter{Sieci konwolucyjne}

Jednym z najpopularniejszych zastosowañ metod \textit{g³êbokiego uczenia} s± tzw. \textit{konwolucyjne sieci neuronowe} (ang. \textit{convolutional neural networks - CNN}). Ze wzglêdu na swoj± architekturê s± one niezwykle skuteczne w niemal wszystkich zagadnieniach wizji komputerowej (ang. \textit{computer vision - CV}). W poni¿szym rozdziale zaczniemy od opisu zjawiska \textit{inwariancji} - wa¿nego dla zrozumienia ogromnego sukcesu sieci konwolucyjnych. Nastêpnie dok³adnie zdefiniujemy sieci, a tak¿e rozmaite pojêcia pojawiaj±ce siê w nomenklaturze ich architektur, po krótce opiszemy najwa¿niejsze historycznie sieci. Na koñcu za¶ bardziej szczegó³owo  opiszemy tzw. sieci residualne - stanowi±ce podstawê implementacji sieci neuronowej, stworzonej w ramach tej pracy. 

\section{Inwariancja}

W rozdziale opisuj±cym szczegó³y dzia³ania sieci neuronowych wspomniali¶my o tym, ¿e struktura sieci neuronowej wraz z wagami j± parametryzuj±cymi koduje pewn± ustalon± hierarchiê cech niezbêdnych do rozwi±zania postawionego przed ni± problemu. Powinny one zatem odwzorowywaæ wiêkszo¶æ w³asno¶ci, które posiadaj± rzeczywiste struktury rozwa¿anych problemów. Jedn± z takich w³asno¶ci jest tzw. w³asno¶æ \textit{inwariancji}, czyli zamkniêto¶æ pewnej cechy na przekszta³canie argumentów przy pomocy ustalonej rodziny przekszta³ceñ. I tak np. cecha bycia okiem przez fragment obrazu lub zdjêcia jest zamkniêta na przekszta³cenia skalowania, przesuniêcia oraz obroty. Kwestia bycia d¼wiêkiem s³owa \textit{mama} jest zamkniêta na zmiany tonu g³osu, g³o¶no¶æ, a tak¿e umiejscowienie na ¶cie¿ce d¼wiêkowej. Przyk³ady mo¿na mno¿yæ - jednak zauwa¿my, ¿e w³asno¶æ inwariancji poci±ga za sob± dwie bardzo powa¿ne konsekwencje:

\begin{itemize}
\item Je¶li uda nam siê uchwyciæ inwariancjê przy pomocy struktury sieci, mo¿emy uzyskaæ kompresjê wiedzy, gdy¿ mnogo¶æ cech, spo¶ród których ka¿da powsta³a jako przekszta³cenie innej, bêdzie reprezentowana w sieci jako jedna.
\item W przypadku niemo¿no¶ci wychwycenia takiej inwariancji, skala trudno¶ci dramatycznie wzrasta, poniewa¿:
\begin{itemize}
\item Ka¿da \textit{realizacja} danej abstakcyjnej cechy musi zostaæ kodowana w sieci osobno.
\item Dla ka¿dej z takich realizacji musi istnieæ co najmniej jeden element w zbiorze treningowym, w którym ona wystêpuje. 
\end{itemize}
\end{itemize}

Aby zrozumieæ skalê problemu, spróbujmy sobie wyobraziæ przypadek, w którym chcieliby¶my nauczyæ sieæ neuronow± rozpoznawania oka na obrazku, w przypadku w którym nasza sieæ nie mog³aby realizowaæ w³asno¶ci \textit{inwariancji} ze wzglêdu na przesuniêcia na obrazku. W skrajnym przypadku musieliby¶my kodowaæ w³asno¶æ bycia ¶rodkiem oka dla ka¿dego piksela z osobno, co sprawia, ¿e problem jest o rz±d wielko¶ci trudniejszy, ni¿ w przypadku gdy mogliby¶my cechê bycia okiem zakodowaæ raz i \textit{zamkn±æ} nasz± strukturê ze wzglêdu na przekszta³cenie translacji.

\section{Architektura sieci konwolucyjnych}

Sieci konwolucyjne to opisana w \cite{conv} i rozwiniêta przez Yana LeCuna oraz Geoffrey'a Hintona architektura, która pozwala uchwyciæ inawariancjê ze wzglêdu na translacje w obrêbie wektora wej¶æ. Matematyczna struktura stoj±ca za sieciami konwolucyjnymi jest banalnie prosta. Oznaczmy przez $P_{i_{1}, i_{2}, \dots. i_{k}}\!: \mathbb{R}^{n} \rightarrow \mathbb{R}^{k}$, gdzie $n \geq k$, operator rzutowania, tzn. 

$$P_{i_{1}, i_{2}, \dots. i_{k}}\left(x_{1}, x_{2}, \dots, x_{n}\right) = \left(x_{i_1}, x_{i_2}, \dots, x_{i_k}\right).$$

Przez \textit{pojedyncz± warstwê konwolucyjn±} z wagami $w_{0}, w_{1}, \dots, w_{n}$, funkcj± aktywacji $\phi$ i rzutowaniami:

$$\mathsf{P} = \left(\left\{i^{(1)}_{1}, i^{(1)}_{2}, \dots, i^{(1)}_{k}\right\}, \left\{i^{(2)}_{1}, i^{(2)}_{2}, \dots, i^{(2)}_{k}\right\}, \dots, \left\{i^{(l)}_{1}, i^{(l)}_{2}, \dots, i^{(l)}_{k}\right\}\right).$$ 

bêdziemy rozumieæ funkcjê $f^{conv}_{\mathsf{P}} : \mathbb{R}^{n} \rightarrow \mathbb{R}^{k},$ dla której $i-$ta wspó³rzêdna wektora $\left[f^{conv}_{\mathsf{P}}\left(x_{1}, x_{2}, \dots. x_{n}\right)\right]_{i}$ zadana jest wzorem :

$$\left[f^{conv}_{\mathsf{P}}\left((x_{1}, x_{2}, \dots. x_{n}\right)\right]_{i} = 
\phi\left(w_{0} + \sum_{j = 1}^{k} w_{j}x_{j^{(i)}} \right).$$

Zwróæmy uwagê, ¿e powy¿sz± warstwê mo¿na zinterpretowaæ jako warstwê, w której ka¿dy neuron po³±czony jest tylko i wy³±cznie z pewnym $k$-elementowym podzbiorem indeksów argumentu, a tak¿e, ¿e wszystkie neurony wspó³dziel± wagi miêdzy sob±. Pozwala to na inwariancjê w tym sensie, ¿e wagi $w_0, w_1, \dots, w_n$ uczestnicz± w wykrywaniu pewnej cechy w kodowanych przez rzutowania regionach obrazu. 

Przedstawiona przez nas definicja konwolucyjnych sieci neuronowych jest bardzo ogólna. W szczególno¶ci nie do koñca jasnym mo¿e byæ sk±d wziê³o siê okre¶lenie sieci jako \textit{konwolucyjnej}. Pewnym wyt³umaczeniem mog± byæ przyk³ady na poni¿szym obrazku przedstawiaj±ce dwie historycznie pierwsze topologie sieci konwolucyjnych (por. \figurename{ \ref{2d-conv}}, \figurename{ \ref{1d-conv}}).

\begin{figure}\label{2d-conv}
\centering 
\includegraphics[scale=0.7]{2d_conv.png}
\caption{Przyk³ad dwuwymiarowej sieci konwolucyjnej. Obliczenia mo¿na interpretowaæ jako z³o¿enie splotu wag $w_1,\dots,w_n$ z warto¶ciami z dwuwymiarowej macierzy oraz funkcji aktywacji.}
\end{figure}

\begin{figure}\label{1d-conv}
\centering 
\includegraphics[scale=0.7]{1d_conv.png}
\caption{Przyk³ad jednowymiarowej sieci konwolucyjnej. Obliczenia mo¿na interpretowaæ jako z³o¿enie splotu wag $w_1,\dots,w_n$ z warto¶ciami z wektora oraz funkcji aktywacji.}
\end{figure}

Oczywi¶cie warstwy konwolucyjne mo¿na ze sob± sk³adaæ, jedna po drugiej. Prowadzi to do uczenia inwariantnych ze wzglêdu na translacjê cech z innych inwariantnych na przesuniêcia konceptów nauczonych przez ni¿sze warstwy. 

\subsection{Najpopularniejsze rzutowania}

Definicja sieci konwolucyjnych przedstawiona powy¿ej jest bardzo ogólna - w wiêkszo¶ci przypadków mo¿na rzutowania przedstawiæ w sposób znacznie bardziej zwiêz³y. W poni¿szych rozwa¿aniach ograniczymy siê do tzw. \textit{konwolucji dwuwymiarowych} które mo¿na interpretowaæ jako konwolucje obrazkowe. Przyjmijmy ponadto kilka dodatkowych za³o¿eñ:

\begin{itemize}
\item \textit{Warstw± konwolucyjna} bêdziemy okre¶laæ zbiór wielu \textit{pojedynczych warstw konwolucyjnych} opartych na tym samym rzutowaniu $\mathsf{P}$.
\item Wej¶ciem oraz wyj¶ciem z warstwy konwolucyjnej bêd± macierze o kszta³cie $(w, h, c)$, gdzie $w$ to szeroko¶æ obrazka, $h$ to wysoko¶æ, natomiast $c$ to tzw. wymiar cech (lub kana³ów - ang. \textit{channels}) bêd±cy równie¿ wymiarem wzd³u¿ którego sk³adane s± \textit{pojedyncze wartswy konwolucyjne}. Ostatni wymiar mo¿emy tak¿e interpretowaæ w nastêpuj±cy sposób:
\begin{itemize}
\item W wypadku gdy argumentami ca³ej sieci s± kolorowe obrazy typu \textit{RGB} wymiar kana³ów ma warto¶æ $3$ i mo¿emy je interpretowaæ jako wektor zawieraj±cy warto¶ci poszczególnych kolorów,
\item W wypadku gdy argumentami ca³ej sieci s± obrazy czarnobia³e -  wymiar kana³ów ma warto¶æ $1$ i mo¿emy je interpretowaæ jako jednowymiarowy wektor zawieraj±cy warto¶æ odcienia szaro¶ci (ang. \textit{grayscale}),
\item W wypadku warstw niewej¶ciowych - wymiar kana³ów nale¿y interpretowaæ jako kana³ trzymaj±cy warto¶ci otrzymane z obliczeñ w poprzedniej warstwie.
\end{itemize}
\item Przez \textit{filtr} bêdziemy rozumieæ  \textit{pojedyncz± warstwê konwolucyjn±}. Jest on to¿samy z trójwymiarow± macierz± o wymiarach $(f_w, f_h, c)$ ($f_w$ bêdziemy okre¶laæ mianem \textit{szeroko¶ci} filtra, $f_h$ bêdziemy okre¶laæ mianem \textit{wysoko¶ci} filtra, natomiast $c$ jest równe warto¶ci wymiaru kana³ów warstwy wej¶ciowej filtra) wraz z funkcj± aktywacji.
\item Rzutowaniem o kroku (ang. \textit{stride}) $(s_w, s_h)$ oraz rozmiarze filtra $(f_w, f_h, c)$ bêdziemy nazywaæ zbiór (dla wszystkich poni¿szych przypadków $c'\in\{0, \dots, c- 1\}$, $k \in \{0, \dots, f_w - 1)$ oraz $l \in \{0, \dots, f_h - 1\}$  zak³adamy, ¿e dla wymiarów wykraczaj±cych poza rozmiar macierzy $x_{i, j, k} = 0$ oraz ustalamy liczenie jej wymiarów od $0$):
\begin{itemize}
\item $\left\{\left(s_w * i + k, s_h * j + l, c'): i \in \{0, \dots,\lfloor\frac{w}{s_w}\rfloor\}, j \in \{0,\dots,\lfloor\frac{h}{s_h}\rfloor\}\right)\right\}$ dla tzw. \textit{braku dope³nienia}, (ang. \textit{valid padding}),
\item $\left\{\left(s_w * i + k, s_h * j + l, c'\right): i \in \{-\lfloor\frac{f_w}{2}\rfloor, \dots,\lfloor\frac{w + \lfloor\frac{f_w}{2}\rfloor}{s_w}\rfloor\}, j \in \{-\lfloor\frac{f_h}{2}\rfloor, \dots, \frac{\lfloor\frac{h + f_h}{2}\rfloor}{s_h}\}\right\}$ dla tzw. \textit{ dope³nienia identycznego}, (ang. \textit{same padding}).
\end{itemize}
\end{itemize}

Rzutowania te mo¿na zinterpretowaæ jako wycinanie prostok±tów rozmiaru $(f_w, f_h)$ z obrazka. Na parametry $(s_w, s_h)$ mo¿na natomiast spojrzeæ jak na liczbê kroków, któr± nale¿y zrobiæ w lewo ($s_w$) lub w dó³ $(s_h)$ aby wyci±æ  kolejny. Dope³nienia determinuj± czy wycinane kwadraty bêd± wycinane tylko i wy³±cznie z macierzy wej¶ciowej (brak dope³nienia) lub czy dodatkowe $0$ bêd± dopisane dooko³a obrazka / mapy cech w celu utrzymania rozmiaru wyj¶ciowej mapy cech proporcjonalnego do rozmiaru macierzy wej¶ciowej.

\begin{figure}
\centering 
\includegraphics[scale=0.6]{conv1.png}
\caption{Przyk³ad obrazuj±cy dzia³anie filtrów konwolucyjnych.}
\end{figure}

\subsection{Pooling}

W sporej czê¶ci zastosowañ jako krok wiêkszo¶ci warstw sieci ustala siê wektor $(1, 1)$, co przy u¿yciu dope³nienia identyczno¶ciowego powoduje, ¿e rozmiary $(w, h)$ macierzy wej¶ciowej i wyj¶ciowej s± identyczne. W zwi±zku z tym, ¿e wymiar $c$ obydwu tych macierzy jest czêsto wiêkszy od $100$ powoduje to powa¿ne problemy pamiêciowe przy obliczeniach wykonywanych w sieci. Jednym z rozwi±zañ tego problemu jest zastosowanie tzw. \textit{poolingu}. Mo¿emy zinterpretowaæ go jako filtr konwolucyjny dla którego zachodzi $(f_w, f_h) \approx (s_w, s_h)$. Powoduje to $(s_w * s_h)$-krotne zmniejszenie rozmiaru macierzy wyj¶ciowej i pozwala ograniczyæ pamiêæ potrzebn± do wykonania obliczeñ.

Dwa najczê¶ciej spotykane rodzaje \textit{poolingu} to tzw. \textit{max pooling} w którym funkcj± aktywacj± jest funkcja $\max$ oraz \textit{mean pooling, avg (average) pooling} - gdzie jako aktywacjê stosuje siê ¶redni± wszystkich elementów rzutowania (por \figurename{ \ref{pool}}).

\begin{figure}\label{pool}
\centering 
\includegraphics[scale=0.5]{pools.png}
\caption{Przyk³ad obrazuj±cy dzia³anie \textit{poolingu}.}
\end{figure}

\subsubsection{Pooling globalny (ang. \textit{global pooling})}

Specjalnym przypadkiem \textit{poolingu} jest tzw. \textit{pooling globalny} (ang. \textit{global pooling}), w którym $(f_w, f_h) = (w, h)$. Wraz z brakiem dope³nieñ powoduje to zmniejszenie rozmiaru wyj¶ciowej macierzy do rozmiaru $(w, h) = (1, 1)$ co sprawia, ¿e macierz tak± mo¿emy interpretowaæ jako wektor. Jest to szczególnie przydatne w przypadku gdy rozwi±zujemy zadanie np. klasyfikacji lub regresji, poniewa¿ ostatnie warstwy takich sieci musz± mieæ naturê wektorow± (klasa lub warto¶ci $\mathbb{X}_y$ s± najczê¶ciej kodowane wektorowo) - wiêc w sieci musi istnieæ moment, w którym kolejne warstwy zaczynaj± mieæ tylko i wy³±cznie naturê wektorow±. Przyk³adem takiej warstwy jest w³a¶nie \textit{pooling globalny}.

\section{Przegl±d najpopularniejszych architektur konwolucyjnych}

Spo³eczno¶æ badaczy sieci konwolucyjnych jest w dzisiejszych czasach bardzo szeroka i nie sposób opisaæ wszystkie trendy i rozwi±zania stosowane przy ich projektowaniu i wykorzystywaniu. Dlatego w tej sekcji przyjrzymy siê najwa¿niejszym historycznie sieciom i przeanalizujemy zastosowane w nich rozwi±zania.

\subsection{Pierwsze sieci konwolucyjne}

Biologicz± podstawê dzia³ania konwolucyjnych sieci neuronowych sformu³owano ok. 1968r. gdy odkryto, ¿e widzenie odbywa siê przy pomocy tzw. pól receptywnych (ang. \textit{receptive fields} \cite{receptive-field}). Jednak za prawdziw± datê ich powstania uznaje siê 1986r. i pracê \cite{backprop} (\textit{nota bene} tê sam± w której zdefiniowano \textit{wsteczn± propagacjê}). Przez wiele lat jednak brak dostatecznie du¿ych zbiorów danych oraz mocy obliczeniowej nie pozwala³ sieciom konwolucyjnym na pokazanie pe³nego potencja³u. Chlubnym wyj±tkiem by³a sieæ LeNet \cite{lenet} autorstwa Yana LeCuna, która dziêki wsparciu biologów pracuj±cych nad percepcj± wzrokow± w mózgu by³a w stanie uzyskaæ satysfakcjonuj±ce rezultaty (por. \figurename{ \ref{lenet}}).
\begin{figure}\label{lenet}
\centering 
\includegraphics[scale=0.5]{lenet.png}
\caption{Schemat architektury sieci \textit{LeNet-5}.}
\end{figure}

\subsection{AlexNet}

Za pierwsz± z tzw. \textit{nowoczesnych} sieci konwolucyjnych uznaje siê tzw. sieæ \textit{AlexNet} \cite{alex-net} (por. \figurename{ \ref{alex-net}}) autorstwa Alexa Krizhevskiego. Osi±gnê³a ona fantastyczne rezultaty w ImageNet Large Scale Visual Recognition Challange 2012 \cite{imagenet} (przez wielu uznawanym za najwa¿niejszy konkurs rozpoznawania obrazu na ¶wiecie), bij±c o kilkana¶cie procent dotychczasowe rekordy algorytmów opartch o klasyczne metody wizji komputerowej. Rozpali³a tym wyobra¼niê badaczy kompletnie zmieniaj±c krajobraz ¶rodowiska specjalistów od wizji komputerowej. W ci±gu 3 lat - sieci konwolucyjne z interesuj±cej ciekawostki sta³y siê dominuj±cym rozwi±zaniem w kategorii rozpoznania obrazu. Przeanalizujmy najwa¿niejsze innowacje wprowadzone przez A. Krizhevskiego w swojej pracy:
\begin{figure}\label{alex-net}
\centering 
\includegraphics[scale=0.9]{alex-net.png}
\caption{Schemat architektury sieci \textit{AlexNet}.}
\end{figure}
\subsubsection{Recitified Linear unit - ReLU}
Pierwsz± z niach by³o wprowadzenie nowej funkcji aktywacji - tzw. \textit{ReLU} (ang. \textit{Rectified Linear Unit)} (por. \figurename{ \ref{relu}}). Jest ona zadana nies³ychanie prostym wzorem:
$$Relu(x) = x\mathbb{I}_{x > 0},$$
z równie prostym wzorem na s³ab± pochodn±:
$$Relu'(x) = \mathbb{I}_{x > 0}.$$
Co wiêcej - obliczenia potrzebne do ich policzenia s± niewyobra¿alnie proste - sprowadzaj± siê \textit{de facto} do wykonania pojedynczego porównania - przez co obliczenia wykonywane przy obliczaniu jej warto¶ci, a tak¿e przy wstecznej propagacji by³y znacznie szybsze do popularnych w tym czasie funkcji $\tanh$ oraz funkcji sigmoidalnej (które wymaga³y chocia¿by obliczenia funkcji eksponencjalnej).
\begin{figure}\label{relu}
\centering 
\includegraphics[scale=0.8]{relu.png}
\caption{Wykres funkcji i s³abej pochodnej \textit{ReLU}.}
\end{figure}

\paragraph{Leaky ReLU}

Jedn± z najwiêkszych wad funkcji \textit{ReLU} by³a kompletna saturacja dla ujemnych warto¶ci argumentów. Aby temu zaradziæ wprowadzono tzw. funkcjê \textit{Leaky ReLU} (por. \figurename{ \ref{leaky-relu}}). Jest to tak w³a¶ciwie rodzina funkcji parametryzowana parametrem $\alpha \in (0, 1)$ zadana wzorem:
$$LeakyReLu_\alpha(x) = x(\mathbb{I}_{x > 0} + \alpha\mathbb{I}_{x \leq 0}),$$
z pochodn±:
$$LeakyReLu'_\alpha(x) = \mathbb{I}_{x > 0} + \alpha\mathbb{I}_{x \leq 0}.$$
Dziêki mniejszej warto¶ci wspó³czynnika kierunkowego funkcja jednocze¶nie nie posiada w³asno¶ci kompletnej saturacji i nie jest liniowa. Ponadto jej obliczenie jej i jej gradientu nadal jest szybkie gdy¿ sprowadza siê w najgorszym przypadku do porównania i mno¿enia przez sta³±.
\begin{figure}\label{leaky-relu}
\centering 
\includegraphics[scale=0.5]{leaky-relu.png}
\caption{Wykres funkcji \textit{Leaky ReLU}.}
\end{figure}

\subsubsection{Obliczenia na kartach graficznych}

Kolejn± przyczyn± niewyobra¿alnego sukcesu \textit{AlexNet} by³ fakt, ¿e obliczenia by³y efektywnie przeniesione na dwie karty graficzne. W zwi±zku z tym, ¿e podstaw± obliczeñ w sieciach neuronowych s± mno¿enia macierzy - które s± równie¿ podstaw± wy¶wietlania obrazu przy pomocy jednostek \textit{GPU} (ang. \textit{Graphic Process Unit}) - Krizhevsky postanowi³ u¿yæ ogromnej mocy obliczeniowej i optymalizacji dostarczanych przez g³ównych producentów kart graficznych w celu przyspieszenia trenowania sieci. Ostatecznie trening \textit{AlexNet} trwa³ ok. 2 tygodni co jak na tamten okres by³o czasem niewiarygodnie krótkim.
\begin{figure}\label{gpu-speed-up}
\centering 
\includegraphics[scale=0.4]{gpu-cpu.png}
\caption{Przyspieszanie kart graficznych oraz zwiêkszanie ró¿nicy pomiêdzy obliczeniami wykonywanymi na GPU / CPU.}
\end{figure}

Co warto wspomnieæ - od tego czasu wielu producentów kart graficznych (szczególnie NVidia) po¶wiêca bardzo wiele pracy na optymalizacjê nowoczesnych kart graficznych specyficznie do \textit{Deep Learningu} dziêki czemu obliczenia algorytmów sieci neuronowych z roku na rok przyspieszaj± coraz bardziej (por. \figurename{ \ref{gpu-speed-up}}).

\subsubsection{Augmentacja obrazów}

Kolejn± technik±, która przynios³a ogromne poprawienie rezultatów by³a tzw. \textit{augmentacja obrazów}. W kolejnych iteracjach obrazki podawane sieci by³y poddawane rozmaitym operacjom, w tym m.in. (por. \figurename{ \ref{aug}}):
\begin{itemize}
\item powiêkszanie - zmniejszanie o losowy czynnik,
\item wycinanie losowego prostok±ta z obrazu,
\item obrót o losowy k±t,
\item losowa symetria wzd³u¿ ustalonych osi,
\item przesuniêcie kolorów o losowy sk³adnik.
\end{itemize}
Wymaga³o to od sieci uchwycenia inwariancji nietylko ze wzglêdu na przesuniêcia, ale tak¿e mnogo¶æ innych transformacji - ograniczaj±c w ten sposób zjawisko przeuczenia. Co wiêcej - w zwi±zku z tym, ¿e zbiór potencjalnych operacji jest nieograniczony (np. ze wzglêdu na mo¿liwe k±ty obrotu czy warto¶ci przesuniêcia) - augmentacja czyni zbiór danych treningowych potencjalnie nieskoñczonym.
\begin{figure}\label{aug}
\centering 
\includegraphics[scale=1.4]{augmentation.png}
\caption{Przyk³ady obrazków uzyskanych z pojedynczego obrazka ze zbioru treningowego przy pomocy losowych augmentacji.}
\end{figure}

\subsubsection{Dropout}

Sieci neuronowe - w zwi±zku ze sw± potencjalnie ogromn± pojemno¶ci± - czêsto do¶wiadczaj± zjawiska przeuczenia. Jednym z rodzajów takiego przeuczenia jest wyodrêbnianie siê w sieci konglomeratu jednostek które ucz± siê \textit{de facto} na pamiêæ podrodziny przyk³adów. Uwa¿a siê, ¿e zjawisko takie pogarsza generalizacjê - dlatego w swojej pracy Krizhevsky po raz pierwszy zastosowa³ specjaln± metodê stworzon± w celu unikniêcia tego zjawiska. W technice tej podczas kolejnych iteracji uczenia ka¿dy neuron jest wy³±czany z prawdopodobieñstwem $p\in(0, 1)$. Dziêki temu - tworzenie siê takiego zespo³u jednostek sieci jest utrudniane przez to, ¿e w ka¿dej z iteracji czê¶æ takiej podsieci jest losowo wy³±czana (por. \figurename{ \ref{dropout}}).
\begin{figure}\label{dropout}
\centering 
\includegraphics[scale=0.5]{dropout-nn.png}
\caption{Przyk³ady architektury sieci w której zastosowane technikê \textit{dropout}.}
\end{figure}

\subsection{VGG}

Kolejn± wa¿n± sieci± w historii rozwoju nowoczesnych g³êbokich sieci konwolucyjnych by³a tzw. sieæ \textit{VGG} \cite{vgg} autorstwa K. Simonyana i A. Zissermana z Oksfordzkiej grupy \textit{Visual Geometry Group} (sk±d nazwa). Wystêpuje ona w ró¿nych wersjach - w zale¿no¶ci od liczby warstw - \textit{VGG-16} oraz \textit{VGG-19}. Co ciekawe, znajduje siê w tym zestawieniu ze wzglêdu na znacz±ce poprawienie rezultatu - w roku og³oszenia nie pobi³a nawet rekordu w ImageNet 2014 \cite{imagenet}. To, co okaza³o siê kluczowym dla jej popularno¶ci to niewiarygodnie prosta teleskopowa architektura, w której kolejne filtry maj± ten sam rozmiar ($(f_w, f_h) = (3, 3)$), a wyst±pienie \textit{poolingu maksymalnego} kompensowane jest podwojeniem ilo¶ci filtrów (por. \figurename{ \ref{vgg}}). Uk³ad ten sta³ siê na tyle inspiruj±cy, ¿e po dzi¶ dzieñ architektura jest zwykle pierwszym wyborem pocz±tkuj±cych \textit{developerów} sieci konwolucyjnych oraz naukowców z innych dziedzin próbuj±cych wykorzystaæ \textit{deep learning} do swoich zastosowañ. 
\begin{figure}\label{vgg}
\centering 
\includegraphics[scale=0.5]{vgg-19.png}
\caption{Schemat architektury sieci \textit{VGG-19}.}
\end{figure}

Co warte podkre¶lenia - aktualnie architektura staje siê lekko archaiczna ze wzglêdu na du¿± ilo¶æ obliczeñ wykonywanych przy maksymalnej rozdzielczo¶ci (w tym przypadku równej $(224, 224)$), co powoduje powa¿ne problemy natury pamiêciowej i czasowej.

\subsection{GoogLeNet}

W tym samym roku co \textit{VGG} powsta³a inna rewolucyjna sieæ zwanna \textit{GoogLeNet} (aluzja do \textit{LeNet}) lub \textit{Incepcj±} (od tytu³u artyku³u \textit{Going Deeper with Convolutions} \cite{inception} oraz popularnego filmu \textit{Incepcja} \cite{inception-movie}). Przyjrzyjmy siê bli¿ej rewolucyjnym zmianom zastosowanym w \textit{Incepcji} (por. \figurename{ \ref{inc-v1}})"
\begin{figure}\label{inc-v1}
\centering 
\includegraphics[scale=0.9]{inception-net.png}
\caption{Schemat architektury sieci \textit{Google Inception v1}}
\end{figure}
\subsubsection{£odyga (ang. \textit{stem}) sieci}

Przez \textit{³odygê} (ang. \textit{stem}) sieci rozumiemy pocz±tkowe warstwy sieci konwolucyjnej które dokonuj± znacz±cej redukcji wymiarowo¶ci na przestrzeni 2-4 warstw. Tak jak wspominali¶my przy okazji sieci \textit{VGG}, pocz±tkowe warstwy sieci s± powodem problemów pamiêciowych poniewa¿ rozdzielczo¶æ map cech jest wtedy najwiêksza. Autorzy zastosowali po kolei: 

\begin{enumerate}
\item Du¿e filtry z dwukrotnym \textit{krokiem}: $(f_w, f_h) = (7, 7)$ i $(s_w, s_h) = (2, 2)$, 
\item \textit{Max Pooling} z $(f_w, f_h) = (3, 3)$ i $(s_w, s_h) = (2, 2)$,
\item Ma³y filtry z pojedynczym \text{krokiem}: $(f_w, f_h) = (3, 3)$ i $(s_w, s_h) = (1, 1)$,
\item \textit{Max Pooling} z $(f_w, f_h) = (3, 3)$ i $(s_w, s_h) = (2, 2)$.
\end{enumerate}

Dziêki tej technice po zaledwie czterech warstwach rozmiary przestrzenne map cech zosta³y zmniejszone po $8$-kroæ (z $(224, 224)$ do $(28, 28)$) co pozwala na znacznie efektywniejsze pamiêciowo i czasowo obliczenia w g³ebszych czê¶ciach sieci.

\subsubsection{Konwolucja $(f_w, f_h) = (1, 1)$ - redukcja wymiarowo¶ci}

Na pierwszy rzut oka konwolucja z $(f_w, f_h) = (1, 1)$ mo¿e nie mieæ wiêkszego sensu - gdy¿ jest \textit{de facto} przekszta³ceniem filtrów z pojedynczego piksela mapy cech. Pozwala jednakowo¿ wykonaæ dwie bardzo przydatne czynno¶ci:

\begin{itemize}
\item Pozwala na skuteczn± redukcjê rozmiaru wyj¶cia z filtrów - mog±c byæ interpretowana jako swoisty semantyczny \textit{pooling} w wymiarze kana³ów.
\item Pozwala na adaptowalne dopasowanie wyj¶cia z wielu warstw sieci konwolucjynch w taki sposób aby posiada³y dok³adnie tak± sam± liczbê filtrów wyj¶ciowych.
\end{itemize}

Szczególnie ta druga w³asno¶æ uczyni konwolucjê przydatn± zarówno dla \textit{GoogLeNet} jak i opisanego w pó¼niejszych czê¶ciach pracy \textit{ResNeta}.

\subsubsection{Klasyfikatory pomocnicze}\label{auxiliary-classifiers}

Kolejn± bardzo interesuj±c± modyfikacj± by³o wprowadzenie tzw. \textit{klasyfikatorów pomocniczych}. Klasyfikatory pomocnicze to dodatkowe wyj¶cia z sieci (umieszczane w warstwach bli¿szych warstwie wej¶ciowej) w których dodawane s± pomocnicze warstwy wyj¶ciowe rozmiaru takiego samego jak ostateczne wyj¶cie z sieci - maj±ce optymalizowaæ dok³adnie tê sam± funkcjê kosztu co jednostki wyj¶ciowe sieci (czêsto nadaje siê tym kosztom ni¿sz± wagê). Celami stosowania klasyfikatorów pomocniczych s±:

\begin{itemize}
\item Przekazywanie rozs±dnego sygna³u ucz±cego (gradientu) dla ni¿szych warstw sieci - dla których \textit{dotarcie} gradientu z ostatnich warstw mo¿e okazaæ siê trudne przez co uczenie sieci jest znacz±co przyspieszane,
\item Zmuszenie ni¿szych warstw sieci aby uczy³y siê \textit{rozs±dnych cech}, tj. takich które same w sobie mog± rozwi±zaæ wyj¶ciowy problem.
\end{itemize}

\subsubsection{Blok incepcyjny - \textit{sieæ w sieci}}
	
Najwa¿niejszym wk³adem \textit{Incepcji} by³o jednakowo¿ wprowadzenie specjalnych bloków incepcyjnych - w których ró¿nego rodzaju konwolucje by³y stosowane do tej samej warstwy wej¶ciowej - po czym wyniki z³±czane by³y wzd³u¿ wymiaru kana³ów (por. \figurename{ \ref{inception-block}}). Pozwala³o to na wykrywanie cech w ró¿nych skalach, a przez to, ¿e obliczenia mog³y byæ wykonywane równolegle - równocze¶nie zwiêkszano skuteczno¶æ i pojemno¶æ sieci bez zbytniego spowalniania obliczeñ. 

\subsubsection{Kolejne wersji Incepcji}

Warto wspomnieæ, ¿e sieæ ta jest bujnie rozwijana. Obecnie dostêpne jest jej ju¿ kilkana¶cie wersji. Opisywanie ich wykracza poza ramy tej pracy - o szczegó³ach mo¿na przeczytaæ w \cite{batch-normalization}, \cite{inception-v3} (warto wspomnieæ o udziale naukowca z naszego wydzia³u - Zbigniewa Wojny) oraz \cite{inception-v4}.

\begin{figure}\label{inception-block}
\centering 
\includegraphics[scale=0.9]{inception-block.jpeg}
\caption{Przyk³ad bloku incepcyjnego - \textit{sieci w sieci}.}
\end{figure}

\subsection{Sieci residualne ResNet}\label{residual-connections}

Ostatni± z nowoczesnych architektur, któr± opiszemy w tej pracy jest \textit{architektura po³±czeñ residualnych - ResNet} \cite{resnet}. Opracowana w laboratoriach firmy Microsoft sieæ wystêpuje w kilkunastu wersjach w zale¿no¶ci od liczby warstw - \textit{ResNet 18, ResNet 34, ResNet 50, ResNet 101 i ResNet 151}. W architekturze tej wykorzystywane s± elementy opisane ju¿ wcze¶niej - czyli klasyfikatory pomocnicze oraz ³odyga. Rewolucyjnym elementem architektur residualnych jest natomiast tzw. \textit{po³±czenie residualne} (ang. \textit{residual connection}) które pozwoli³o na osi±ganie niewyobra¿alnych wcze¶niej g³êboko¶ci.

\subsubsection{Po³±czenia residualne}

\textit{Po³±czeniem residualnym} nazywamy blok warstw konwolucyjnych w którym wyj¶cie z tego bloku zostaje poddane jednej z dwóch nastêpuj±cych operacji:

\begin{itemize}
\item dodania do warstwy wej¶ciowej wyj¶cia z tej warstwy (wymagane jest aby wyj¶cie mia³o dok³adnie taki sam rozmiar $(w, h, c)$ jak wej¶cie (por. \figurename{ \ref{residual}}).
\item do³±czenia do warstwy wej¶ciowej wyj¶cia z tej warstwy (wymagane jest aby wyj¶cie mia³o takie same $w$ i $h$ jak wej¶cie).
\end{itemize}

W architekturach $ResNet$ wykorzystywany jest blok z operacj± dodawania. Intuicyjnym wyt³umaczeniem skuteczno¶ci dzia³ania po³±czeñ residualnych w tym wypadku jest to, ¿e sieæ uczy siê ci±gu kolejnych zaburzeñ poprzednich warstw które prowadz± do dobrego wyniku, zamiast ci±gu transformacji prowadz±cego do celu (transformacje te mog± kompletnie gubiæ naturê swoich argumentów - czêsto znacznie u³atwiaj±c± rozwi±zanie zadania). Dziêki temu - problemy z przekazywaniem sygna³u ucz±cego w ni¿sze warstwy sieci s± znacznie mniejsze - co pozwala na znacz±ce zwiêkszenie g³êboko¶ci sieci.

\begin{figure}\label{residual}
\centering 
\includegraphics[scale=0.9]{residual.png}
\caption{Przyk³ad po³±czenia residualnego.}
\end{figure}

\chapter{Implementacja - zastosowanie sieci konwolucyjnych do rozpoznawania nowotworu jelita grubego}

W poni¿szym rozdziale opiszemy zastosowanie sieci konwolucyjnej do rozpoznania typu tkanki pobranej z jelita grubego. Rozwi±zanie to osi±gnê³o doskona³e wyniki, porównywalne z wynikami przedstawionymi w renomowanym czasopi¶mie naukowym \cite{nature-cancer}. W kolejnych rozdzia³ach opiszemy rozwi±zywany problem, zbiór danych, architekturê sieci oraz porównamy wyniki modelu z najlepszymi uzyskanymi obecnie wynikami \cite{nature-cancer}.

\section{Opis problemu}

Rak jelita grubego (³ac. \textit{carcinoma intestini crassi}) jest jednym z najczê¶ciej rozpoznawanych nowotworów na ¶wiecie. W 2012 roku w Europie rozpoznano 450 000 przypadków raka jelita grubego i 215 000 przypadków zgonów \cite{wiki-cancer}. Jednym ze sposobów rozpoznawania choroby jest analiza obrazów pobranych tkanek uzyskanych przy pomocy mikroskopu elektronowego. Ten w³a¶nie sposób stanowi podstawê algorytmów opisanych w tej pracy.

\section{Opis zbioru danych i dotychczasowych wyników}

W \cite{nature-cancer} badacze przygotowali pierwszy zbiór danych do analizy i porównywania wyników modeli przeznaczonych do rozpoznawania komórek rakowych w tkankach jelita grubego. Poni¿ej opiszemy przedstawiony zbiór danych oraz wyniki uzyskane przez badaczy.

\subsection{Zbiór danych}\label{dataset}

Zbiór danych - opisany w \cite{nature-cancer} sk³ada siê z 5000 kolorowych zdjêæ o rozmiarze $(150, 150)$. Ka¿de z nich przynale¿y do dok³adnie jednej z 8 kategorii:

\begin{enumerate}[label=\alph*.]
\item guz w tkance nab³onkowej (ang. \textit{tumour epithelium}),
\item zr±b prosty (ang. \textit{simple stroma}),
\item zr±b z³o¿ony (ang. \textit{complex stroma}),
\item komórki odporno¶ciowe (ang. \textit{immune cells}),
\item martwa tkanka (ang. \textit{debris}),
\item gruczo³y ¶luzowe (ang. \text{mucosal glands}),
\item gruczo³y ¶luzowe (ang. \textit{adipose tissue}),
\item t³o.
\end{enumerate}
Wszystkie klasy reprezentowane s± równolicznie, a zatem w zbiorze testowym mamy po 625 obrazków ka¿dego typu.

\paragraph{Sposób zebrania} 

Wszystkie obrazki zosta³y wyciête ze zdjêæ tkanek nowotworowych, zrobionych mikroskopem elektronowym o rozdzielczo¶ci $0.5\mu m$. Kolor obrazków zosta³ uzyskany poprzez barwienie hematoksylin± i eozyn±.

\begin{figure}
\centering 
\includegraphics[scale=1.4]{cancer.jpg}
\caption{Przyk³ady obrazków z ka¿dej z klas.}
\end{figure}


\section{Opis sieci i eksperymentu}

W tej sekcji opiszemy architekturê sieci oraz sposób przeprowadzenia eksperymentów. Zaczniemy od przedstawienia schematu sieci wraz ze szczegó³ami procesu trenowania oraz warunku stopu gradientowego algorytmu ucz±cego. Nastêpnie opiszemy procedurê przy pomocy której uzyskali¶my ostateczne wyniki.

\subsection{Opis architektury sieci}

Sieæ u¿yta podczas eksperymentów wzorowana by³a na popularnej \textit{ResNet 18} \cite{resnet} - najp³ytszej sieci z rodziny \textit{ResNet}. Sk³ada siê ona z: 

\begin{enumerate}
\item Dwuwymiarowej ³odygi \textit{£odyga 1},
\item Trzech bloków residualnych z odnog± do \textit{globalnego poolingu maksymalnego} zakoñczonego klasyfikatorem pomocniczym - \textit{Blok 1},
\item Trzech bloków residualnych zakoñczonych \textit{globalnym poolingiem maksymalnym} i klasyfikatorem g³ównym - \textit{Blok 2}.
\end{enumerate}

\paragraph{Wej¶cie}

Wej¶cie do sieci ma rozmiar $(128, 128, 3)$ (rozmiar zosta³ dobrany w celu trzymania siê popularnej w spo³eczno¶ci sieci neuronowych konwencji, wed³ug której rozmiar wej¶cia powinien byæ podzielny przez $32$). Obrazki s± zmniejszane przy pomocy interpolacji dwuliniowej \cite{bilinear-interpolation}.

\paragraph{£odyga}

£odyga sk³ada sie z:

\begin{enumerate}
\item warstwy konwolucyjnej o parametrach filtra $(f_w, f_h, c)\!=\!(7, 7, 64)$ oraz krokach $(s_w, s_h)\!=\!(4, 4)$,
\item \textit{Poolingu maksymalnego} o parametrach filtra $(f_w, f_h)\!=\!(2, 2)$ oraz kroku $(s_w, s_h)\!=\!(2, 2)$.
\end{enumerate}  

\paragraph{Blok 1}

Blok 1 zaczyna siê 3-krotnym powtórzeniem nastêpuj±cego schematu:

\begin{enumerate}
\item warstwy konwolucyjnej \textit{K} o parametrach filtra $(f_w, f_h, c)\!=\!(3, 3, 64)$ oraz krokach $(s_w, s_h)\!=\!(1, 1)$,
\item po³±czenia residualnego, w którym wej¶cie do warstwy \textit{K} dodawane jest do jej wyniku. 
\end{enumerate}
Warto zauwa¿yæ, ¿e powy¿sza operacja jest mo¿liwa poniewa¿ wej¶cie i wyj¶cie warstwy \textit{K} maj± taki sam rozmiar. Zakoñczeniem Bloku 1 jest rozga³êzienie do dwóch odnóg:

\begin{enumerate}
\item \textit{globalnego poolingu u¶rednionego} zakoñczonego warstw± liniow± o rozmiarze wyj¶cia $(8,)$ z funkcj± aktywacji typu $Softmax$ (blok ten jest wej¶ciem do Bloku 2),
\item \textit{poolingiem u¶rednionym} o rozmiarze filtra $(f_w, f_h)\!=\!(2, 2)$ i kroku $(s_w, s_h)\!=\!(2, 2)$.
\end{enumerate}

\paragraph{Blok 2}

Blok 2 (analogicznie do Bloku 1) - zaczyna siê 3-krotnym powtórzeniem nastêpuj±cego schematu:

\begin{enumerate}
\item warstwy konwolucyjnej \textit{K} o parametrach filtra $(f_w, f_h, c)\!=\!(3, 3, 64)$ oraz krokach $(s_w, s_h)\!=\!(1, 1)$,
\item po³±czenia residualnego, w którym wej¶cie do warstwy \textit{K} dodawane jest do jej wyniku. 
\end{enumerate}
Blok 2 zakoñczony jest \textit{globalnym poolingiem u¶rednionym} z³o¿onym z funkcj± liniow± o rozmiarze wyj¶cia $(8,)$, z funkcj± aktywacji $Softmax$. Zakoñczenie to jest jednocze¶nie wyj¶ciem ostatecznym z sieci.

\begin{figure}
\centering 
\includegraphics[scale=0.28]{stem-schema.png}
\caption{Schemat bloku 1 i 2.}
\end{figure}

\begin{figure}
\centering 
\includegraphics[scale=0.42]{network-schema.png}
\caption{Schemat bloku 1 i 2.}
\end{figure}

\paragraph{Interpretacja wyj¶æ}

Obydwa wyj¶cia opisane powy¿ej mo¿na zinterpretowaæ jako rozk³ad prawdopodobieñstwa tego, ¿e podany obrazek przedstawia jedn± z klas opisanych w \ref{dataset}. Kolejno¶æ wspó³rzêdnych jest identyczna jak ta, w \ref{dataset}.

\paragraph{Normalizacja porcjowa oraz funkcja aktywacji} 

Wyj¶cie z ka¿dej warstwy konwolucyjnej poddane jest normalizacji porcjowej. Do znormalizowanego wyniku warstwy wyj¶ciowej zaaplikowana jest funkcja aktywacji typu \textit{Leaky ReLU}. Schemat ten powsta³ na podstawie \cite{yolo}.

\subsection{Szczegó³y funkcji kosztu}

Ostateczna funkcja kosztu zadana jest nastêpuj±ym wzorem:

$$J_\mathcal{X} = -\sum_{x \in \mathcal{X}}\left(0.9 \sum_{i=1}^8 w_i o_i^{out}\log o_i^{out} +0.1\sum_{i=1}^8 w_i o_i^{aux}\log o_i^{aux}\right),$$
gdzie $o^{out}$ jest wynikiem ostatecznego wyj¶cia z sieci, natomiast $o^{aux}$ jest wyj¶ciem z wyj¶cia pomocniczego. $w$ jest nastomiast wektorem wag zadanym wzorem $w_1 = 5$ oraz $w_i = 1$ dla $i = 2, \dots, 8$. Mo¿na zatem zinterpretowaæ obydwa czynniki w powy¿szym wzorze jako ¶redni± wa¿on± \textit{wa¿onych kategorycznych entropii krzy¿owych} (por. \ref{categorical-cross-entropy}) z wektorem wag $w$.  

Intuicyjnie powy¿sza funkcja kosztu nadaje du¿o wiêksze znaczenie (waga $0.9$) funkcji straty g³ównego wyj¶cia, jednocze¶nie przesy³aj±c lekki sygna³ ucz±cy (waga $0.1$) bezpo¶rednio do Bloku 1. Zapobiega to zjawisku znikaj±cego gradientu oraz sprawia, ¿e cechy uczone przez warstwy Bloku 1 same w sobie posiadaj± w³asno¶ci predykcyjne. Waga $w_i = 5$ nadaje znaczne wiêksze znaczenie odpowiedniej klasyfikacji guza. Ma to podnie¶æ skuteczno¶æ modelu w rozpoznawaniu obrazków tego typu.

\subsection{Szczegó³y algorytmu optymalizacyjnego}

Algorytmem ucz±cym by³o stochastyczne uczenie gradientowe (ang. \textit{stochastic gradient descent}) z rozmiarem porcji równym $128$, \textit{momentum} równym $0.9$ oraz \textit{sta³± uczenia} równ± $0.1$. Zastosowany zosta³ równie¿ schemat \textit{redukcji sta³ej uczenia w wypadku wysokiej i sta³ej warto¶ci funkcji kosztu} - \textit{sta³a uczenia} by³a zmniejszana 10-krotnie je¶li na wydzielonym zbiorze testowym (o rozmiarze 20\% zbioru treningowego) maksymalna dok³adno¶æ (ang. \textit{accuracy}) modelu nie uleg³a zwiêkszeniu w ci±gu 10 epok.

\subsection{Szczegó³y procesu uczenia}\label{learning}

Sieæ by³a uczona przez 200 epok. W celu unikniêcia utkniêcia w \textit{s³abym minimum} je¶li po 10 epokach warto¶æ funkcji kosztu nie by³a mniejsza od $2.0$ - uczenie by³o restartowane. Ostatecznym modelem po 200 epokach by³ model który osi±gn±³ najlepsz± dok³adno¶æ na wspomnianym w poprzedniej podsekcji wydzielonym 20-procentowym podzbiorze zbioru treningowego.

\subsection{Szczegó³y implementacji}

Model zosta³ zaimplementowany przy pomocy pakietu \texttt{Keras} \cite{keras} opartym na pakiecie \texttt{TensorFlow} \cite{tensorflow}. Trening przeprowadzony zosta³ dziêki pomocy firmy Microsoft w ramach grantu TODO opisz, dziêki czemu zakupiony zosta³ czas obliczeniowy na maszynie wirtualnej typu \texttt{Azure NC-6} \cite{azure-nc-6}. 

\section{Porównanie wyników}

W \cite{nature-cancer} oprócz zbioru danych, autorzy zaproponowali tak¿e metodê klasyfikacji obrazków w dwóch kategoriach:

\begin{itemize}
\item Przyporz±dkowania danego obrazku do prawid³owej kategorii,
\item Sprawdzenie czy dany obrazek nale¿y do klasy guza tkanki nab³onkowej.
\end{itemize}

Dla klasyfikacji 8-klasowej autorzy przedstawili dok³adno¶æ, a tak¿e ¶rednie \textit{AUC}. W wypadku klasyfikacji \textit{guz vs reszta} autorzy przedstawili tylko dok³adno¶æ.

Wyniki zosta³y uzyskane przy pomocy 10-krotnej walidacji krzy¿owej. 

\subsection{Wyniki uzyskane przez autorów zbioru danych}

W pierwszej z kategorii (klasyfikacji 8-klasowej) najlepszy przedstawiony przez autorów model uzyska³ dok³adno¶æ (ang. \textit{accuracy}) na poziomie $87.4\%$ oraz ¶rednie $AUC$ równe $0.976$. W kategorii rozpoznania raka autorzy uzyskali wynik dok³adno¶ci równy $98.6\%$.

\subsection{Wyniki uzyskane przez model opisany w tej pracy}

\paragraph{Szczegó³y uzyskiwania ostatecznych rezultatów}

Wynikiem obu wyj¶æ z sieci jest rozk³ad prawdopodobieñstwa nad potencjalnymi 8 klasami. Ostateczn± predykcjê uzyskujemy poprzez:

\begin{enumerate}
\item W przypadku klasyfikacji 8-klasowej: wybranie klasy dla której ostateczne wyj¶cie z sieci by³o najwy¿sze. W wypadku remisów wybierana jest klasa o najni¿szym indeksie,
\item W przypadku wykrywania komórek guza: Klasa guza przyporz±dkowywana jest wtedy gdy wynik przypisany klasie guza przez ostateczne wyj¶cie przekroczy warto¶æ $0.5$.
\end{enumerate}

W niniejszej pracy powtórzyli¶my eksperyment wykonany przez autorów artyku³u \cite{nature-cancer}.

Model opisany w tej pracy w kategorii klasyfikacji 8-klasowej uzyska³ skuteczno¶æ na poziomie $92\%$ oraz ¶rednie \textit{AUC} na poziomie $0.974$. W kategorii rozpoznawania guzów uzyska³ natomiast skuteczno¶æ na poziomie $98.2\%$. 

\subsubsection{Porównanie}

Model opisany w tej pracy znacz±co podniós³ wynik dok³adno¶ci w kategorii rozpoznania klasy zdjêæ (wzrost o $4.6\%$) i osi±gn±³ porównywalne (acz minimalnie gorsze rezultaty) w kategorii ¶redniego \textit{AUC} oraz dok³adno¶ci w wykrywaniu komórek rakowych. Co godne podkre¶lenia - podczas analizy wyników okaza³o siê, ¿e w jednym z eksperymentów walidacji krzy¿owej model najprawdopodobniej utkn±³ w nieoptymalnym minimum uzyskuj±c wyra¼nie gorsze wyniki dok³adno¶ci w klasyfikacji 8-klasowej ($78\%$ przy ¶redniej z pozosta³ych eksperymentów $93.5\%$)oraz klasyfikacji \textit{guz vs reszta} ($97.2\%$ przy ¶redniej z pozosta³ych eksperymentów $98.2\%$). Sta³o siê to pomimo zastosowania specjalnego warunku stopu opisanego w \ref{learning}. Oczekujemy, ¿e poprawienie tego warunku powinno pomóc w unikniêciu takiej sytuacji w przysz³o¶ci. Po analizie wyników okaza³o siê, ¿e spowodowa³o to równie¿ znaczne obni¿enie i nietypowe zachowanie krzywej ROC w wypadku rozpoznania klasy t³a (zobacz \ref{roc-marcin}).
 

\begin{figure}
\includegraphics[scale=0.65]{kather-cm.png}
\caption{Macierz b³êdów uzyskana w kategorii klasyfikacji 8-klasowej przez \cite{nature-cancer}.}
\end{figure}

\begin{figure}
\centering 
\includegraphics[scale=0.27]{marcin-cm.png}
\caption{Macierz b³êdów uzyskana przez model opisany w tej pracy.}
\end{figure}

\begin{figure}
\centering 
\includegraphics[scale=0.65]{roc-kather.png}
\caption{Krzywe ROC uzyskane przez autorów \cite{nature-cancer}.}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.42]{marcin-roc.png}\label{roc-marcin}
\caption{Krzywe ROC uzyskane przez model opisany w tej pracy.}
\end{figure}

\chapter{Dyskusja}

Oznaczanie komórek rakowych na obrazach uzyskanych przy pomocy mikroskopu elektronowego stanowi kluczow± czynno¶æ w diagnozie i badaniu przyczyn raka jelita grubego. Automatyzacja tej techniki przy pomocy sztucznej inteligencji pozwala na jej znaczne przyspieszenie oraz znacz±ce zmniejszenie kosztów. Wed³ug naszej wiedzy stworzony przez nas model jest pierwszym modelem \textit{deep learningowym} wytrenowanym wy³±cznie na zbiorze danych z \cite{nature-cancer} - inne prace stosuj±ce tê technikê wykorzystywa³y tê kolekcjê jak± jedn± z wielu w celu zwiêkszenia ilo¶ci przyk³adów treningowych.

\section*{Kolejne kroki}

Modele g³êbokiego uczenia odnosz± liczne sukcesy w rozpoznawaniu obrazów \cite{resnet, inception}, d¼wiêków i muzyki \cite{wavenet} czy jêzyka naturalnego \cite{deep-learning-translation} - jednak zazwyczaj zbiory danych wymagane do ich efektywnego uczenia s± o rz±d rozmiaru wiêksze ($> 50000$) ni¿ zbiór na którym zosta³ wytrenowany zaimplementowany model. Fakt, ¿e architektura opisana w tej pracy czyni mo¿liwym analizê histopatologiczn± w oparciu o tak ma³e zbiory danych pozwala ¿ywiæ nadziejê, ¿e zastosowanie jej do podobnych kolekcji zdjêæ tkanek innych narz±dów powinno daæ podobnie zadowalaj±ce rezultaty.

Planowane jest dalsze rozwijanie architektury w celu poprawy jej rezultatów oraz jej adaptacja do wykorzystania w paradygmacie tzw. \textit{bayesowskiego deep-learningu} w oparciu o technikê \textit{wariacyjnego dropoutu} \cite{variational-dropout}. Dziêki tej technice model dostarcza nie tylko predykcjê klasy obrazka, ale równie¿ estymacjê niepewno¶ci swojego wyniku. Dziêki temu mo¿liwy staje siê np. scenariusz zastosowania techniki \textit{active learning} \cite{active-learning} dziêki której obrazki co do których model ma najwiêksze w±tpliwo¶ci bêd± kierowane do rêcznego oznaczania. Pozwoli to na dalsz± poprawê skuteczno¶ci modelu oraz niemal automatyczne powiêkszanie istniej±cych zbiorów danych. Perspektywa kompletnego wyrugowania ludzkiego tagowania z rozpoznawania raka jelita grubego jawi siê zatem jako znacznie bli¿sza. 

\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}

\bibitem{twarze}
DeepFace: Closing the Gap to Human-Level Performance in Face Verification,
Yaniv Taigman, et al.
Conference on Computer Vision and Pattern Recognition (CVPR) 24 czerwca 2014.

\bibitem{znaki}
Recognizing Traffic Signs Using a Practical Deep Neural Network,
Hamed H. Aghdam, et al.
Robot 2015: Second Iberian Robotics Conference, 2 grudnia 2015.

\bibitem{mnist}
Gradient-based learning applied to document recognition,
LeCun et al.,
Proceedings of the IEEE, 86(11):2278-2324, November 1998.

\bibitem{perceptron}
The Perceptron: A probabilistic model for
information storage and organization
in the brain,
Frank Rosenblatt, 
Psychological Review, Vol.65, No. 6, 1958

\bibitem{mccul-pitts}
A logical calculus of the ideas immament in nervous activity,
Warren S.McCulloch and Walter Pitts,
Bulletin of Mathematical Biophysics, vol.5 1943

\bibitem{minsky-papert}
Perceptrons: An Introduction to Computational Geometry,
Marvin Minsky i Seymour Papert,
The MIT Press, Cambridge MA

\bibitem{backprop}
Learning representations by back-propagating errors,
David E. Rumelhart et al.,
Nature, 323	(6088) Pa¼dziernik 1986

\bibitem{conv}
Decomposition of surface EMG signals into single fiber action potentials by means of neural network,
Daniel Graupe, et al.,
Proc. IEEE International Symp. on Circuits and Systems, 1989

\bibitem{popper}
Logika odkrycia naukowego,
Karl Popper,
PWN, 1977

\bibitem{recurrent}
Generalization of backpropagation with application to a recurrent gas market model,
P. J. Werbos,
Neural Networks, 1, 1988.

\bibitem{cybenko}
Approximations by superpositions of sigmoidal functions,
G. Cybenko,
Mathematics of Control, Signals, and Systems 2 (4) (1988), 303-314

\bibitem{hornik}
Approximation Capabilities of Multilayer Feedforward Networks,Kurt Hornik (1991)
K. Hornik,
Neural Networks, 4 (2) (1991), 251?257

\bibitem{adam}
A Method for Stochastic Optimization,
D.P. Kingma, J. Ba,
CoRR, 2014 

\bibitem{minibatch}
Efficient mini-batch training for stochastic optimization,
Mu Li, et al.,
Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, 661-670 

\bibitem{randomsearch}
Random Search for Hyper-Parameter Optimization,
J. Bergstra, Y. Bengio,
Journal of Machine Learning Research 13 (2012) 281-305

\bibitem{lasso}
Regression Shrinkage and Selection via the lasso,
R. Tibshirani,
Journal of the Royal Statistical Society. Series B (methodological) 58 (1). Wiley: 267?88

\bibitem{bengio}
Learning Deep Architectures for AI,
Y. Bengio,
Foundations and Trends in Machine Learning Vol. 2, No. 1 (2009) 1?127

\bibitem{sentiment}
Domain Adaptation for Large-Scale Sentiment Classification:
A Deep Learning Approach,
X. Glorot et al.,
Proceedings  of  the  28th International  Conference  on  Machine  Learning,  Bellevue,  WA,  USA,  2011.

\bibitem{lem}
Dialogi,
S. Lem,
Wydawnictwo Literackie 1957 

\bibitem{vapnik-bet}
https://www.wired.com/2014/08/deep-learning-yann-lecun/

\bibitem{manifold-learning}
Manifold Learning: The Price of Normalization,
Y. Goldberg et al.,
Journal of Machine Learning Research 9 (2008) 1909-1939

\bibitem{gradient-descents}
An overview of gradient descent optimization algorithms,
http://ruder.io/optimizing-gradient-descent/

\bibitem{nadam}
Incorporating Nesterov Momentum into Adam,
T. Dozat,
Stanford CS 229 Projects - 2015

\bibitem{loss-landscapes}
Towards Understanding Generalization of Deep
Learning: Perspective of Loss Landscapes,
L. Wu et al.,
https://arxiv.org/pdf/1706.10239.pdf

\bibitem{logistic-regression}
The regression analysis of binary sequences (with discussion),
Cox, DR,
J Roy Stat Soc B. 20: 215 - 242 1958

\bibitem{skip-connections}
Skip Connections Eliminate Singularities,
A. E. Orhan, Xaq Pitkow,
arXiv:1701.09175

\bibitem{curse-of-dimensionality}
Nearest Neighbour Searches and the Curse of Dimensionality,
R. B. Marimont M. B. Shapiro,
IMA Journal of Applied Mathematics, Volume 24, Issue 1, 1 August 1979, Pages 59-70

\bibitem{unfolding-rnn}
Generalization of Back-Propagation to Recurrent Neural Networks,
F. J. Pineda,

\bibitem{zeiler-fergus}
Visualizing and Understanding Convolutional Networks,
M. D. Zeiler, R. Fergus,
arXiv:1311.2901

\bibitem{hierarchical}
Learning hierarchical categories in deep neural networks,
A. M. Saxe et al.,
Proceedings of the 35th annual meeting of the Cognitive Science Society. (pp. 1271-1276), 2013

\bibitem{res-net}
Deep Residual Learning for Image Recognition,
K. He et al.,
arXiv:1512.03385 

\bibitem{batch-normalization}
Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,
S. Ioffe, Ch. Szegedy,
arXiv:1502.03167 

\bibitem{kullback-leibler}
On information and sufficiency,
S. Kullback, R.A. Leibler,
Annals of Mathematical Statistics 22, 79-86

\bibitem{lenet}
Gradient-Based Learning Applied to Document Recognition,
Yann LeCun et al.,
Proc. of IEEE, November 1998

\bibitem{receptive-field}
Receptive fields and functional architecture of monkey striate cortex,
D. H. Hubel, T. N. Wiesel,
The Journal of Physiology. 195 (1): 215?243

\bibitem{alex-net}
ImageNet Classification with Deep Convolutional
Neural Networks,
A. Krizhevsky et al,
NIPS 2012

\bibitem{imagenet}
ImageNet Large Scale Visual Recognition Challenge,
Russakovsky et al.,
arXiv:1409.0575 

\bibitem{vgg}
Very Deep Convolutional Networks for Large-Scale Image Recognition,
K. Simonyan, A. Zisserman,
arXiv:1409.1556

\bibitem{inception}
Going Deeper with Convolutions,
Ch. Szegedy et al.,
arXiv:1409.4842 

\bibitem{inception-movie}
Inception (2010),
www.imdb.com/title/tt1375666
IMDB

\bibitem{inception-v3}
Rethinking the Inception Architecture for Computer Vision,
Ch. Szegedy et al,
arXiv:1512.00567 

\bibitem{inception-v4}
Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning,
Ch. Szegedy et al.,
arXiv:1602.07261

\bibitem{resnet}
Deep Residual Learning for Image Recognition,
K. He, et al.,
arXiv:1512.03385

\bibitem{dropout}
Improving neural networks by preventing co-adaptation of feature detectors,
G. Hinton,
arXiv:1207.0580

\bibitem{nature-cancer}
Multi-class texture analysis in colorectal cancer histology,
J.N. Kather,
Scientific Reports 6, Article number: 27988 (2016)

\bibitem{wiki-cancer}
Rak jelita grubego,
Wikipedia Polska

\bibitem{keras}
Keras,
Francois Chollet et al.,
2015,
https://github.com/fchollet/keras

\bibitem{tensorflow}
TensorFlow: Large-scale machine learning on heterogeneous systems,
Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo,
Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis,
Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow,
Andrew Harp, Geoffrey Irving, Michael Isard, Rafal Jozefowicz, Yangqing Jia,
Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Mike Schuster,
Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Jonathon Shlens,
Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker,
Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas,
Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke,
Yuan Yu, and Xiaoqiang Zheng,
2015. Software available from tensorflow.org

\bibitem{azure-nc-6}
Azure N-Series preview availability,
https://azure.microsoft.com/en-us/blog/azure-n-series-preview-availability/

\bibitem{choromanska}
The Loss Surfaces of Multilayer Networks,
A. Choromanska et al.,
arXiv:1412.0233

\bibitem{bilinear-interpolation}
Comparision of Interpolating Methods for Image Resampling,
J. A. Parker et al.,
IEEE Trans Med Imaging. 1983;2(1):31-9.

\bibitem{yolo}
YOLO9000: Better, Faster, Stronger,
J. Redmond, A. Fahradi,
arXiv:1612.08242

\bibitem{wavenet}
WaveNet: A Generative Model for Raw Audio,
A. vd Oord et al.,
arXiv:1609.03499

\bibitem{deep-learning-translation}
Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation,
Y. Wu et al.,
arXiv:1609.08144

\bibitem{active-learning}
Deep Bayesian Active Learning with Image Data,
Y. Gal et al.,
arXiv:1703.02910

\bibitem{variational-dropout}
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning,
Y. Gal et al.,
arXiv:1506.02142

\end{thebibliography}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
